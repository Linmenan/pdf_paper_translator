import os
import json
import base64
import uvicorn
import fitz  # PyMuPDF
from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any
from fastapi.responses import FileResponse
import prompts
import asyncio
from fastapi.responses import StreamingResponse
# å¼•å…¥æ ¸å¿ƒåº“
import workflow_utils as wf

app = FastAPI()

# --- 1. å…¨å±€é…ç½® (ç¡¬ç¼–ç è·¯å¾„) ---
# ç”¨æˆ·ä¸å¯ä¿®æ”¹ï¼Œå‰ç«¯ä¹Ÿä¸æ˜¾ç¤º
CONFIG = {
    "pdf_dir": "./academic_papers",
    "extract_dir": "./extracted_output",
    "llm_dir": "./llm_output",
    "vis_dir": "./vis_output"
}

# è‡ªåŠ¨åˆ›å»ºç›®å½•
for d in CONFIG.values():
    os.makedirs(d, exist_ok=True)

# æŒ‚è½½é™æ€èµ„æº
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/output", StaticFiles(directory="vis_output"), name="output")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

@app.get("/")
async def read_index():
    # è¿™æ ·è®¿é—® http://localhost:8000 å°±ä¼šç›´æ¥æ˜¾ç¤ºç½‘é¡µ
    return FileResponse("static/index.html")

# --- æ•°æ®æ¨¡å‹ ---
class LayoutData(BaseModel):
    page_index: int
    items: List[Dict[str, Any]] # åŒ…å« rect, type, id, role

class SaveLayoutRequest(BaseModel):
    filename: str
    layout_data: Dict[str, List[Dict[str, Any]]] # Keyæ˜¯é¡µç å­—ç¬¦ä¸²

# --- API: é¦–é¡µæç¤ºè¯ ---
@app.get("/api/config/prompts")
def get_prompts_config():
    """è¿”å›åç«¯çœŸå®ä½¿ç”¨çš„ Promptï¼Œä¾›å‰ç«¯é¢„è§ˆ"""
    return {
        "meta": prompts.SYSTEM_PROMPT_META,
        "body": prompts.SYSTEM_PROMPT_BODY,
        "asset": prompts.SYSTEM_PROMPT_ASSET,
        "correction": prompts.SYSTEM_PROMPT_CORRECTION
    }

# --- API: é¦–é¡µè·å–é¡¹ç›®åˆ—è¡¨ ---
@app.get("/api/papers")
def list_papers():
    """æ‰«æç›®å½•ï¼Œè¿”å›æ‰€æœ‰PDFåŠå…¶ç²¾ç¡®çŠ¶æ€"""
    papers = []
    if not os.path.exists(CONFIG["pdf_dir"]):
        return []
    
    for f in os.listdir(CONFIG["pdf_dir"]):
        if f.lower().endswith(".pdf"):
            raw_name = wf.sanitize_filename(f)
            status = "æœªå¼€å§‹"
            
            # è·¯å¾„å®šä¹‰
            report_path = os.path.join(CONFIG["vis_dir"], raw_name, f"{raw_name}_Report.html")
            result_path = os.path.join(CONFIG["llm_dir"], f"{raw_name}_llm_result.txt")
            cache_path = os.path.join(CONFIG["llm_dir"], f"{raw_name}_llm_cache.json")
            context_path = os.path.join(CONFIG["extract_dir"], f"{raw_name}_context.txt")
            
            # 1. ä¼˜å…ˆçº§æœ€é«˜ï¼šå·²ç”Ÿæˆ HTML æŠ¥å‘Š
            if os.path.exists(report_path):
                status = "å·²å®Œæˆ"
            # 2. å…¶æ¬¡ï¼šLLM ç»“æœæ–‡æœ¬å·²ç”Ÿæˆ (ç¿»è¯‘æµèµ°å®Œ)
            elif os.path.exists(result_path):
                status = "ç¿»è¯‘å®Œæˆ"
            # 3. å†æ¬¡ï¼šæœ‰ç¼“å­˜æ–‡ä»¶ (è¯´æ˜æ­£åœ¨ç¿»è¯‘æˆ–ä¸Šæ¬¡ä¸­æ–­)
            elif os.path.exists(cache_path):
                try:
                    with open(cache_path, 'r', encoding='utf-8') as cf:
                        data = json.load(cf)
                        tasks = data.get("tasks", [])
                        success_count = sum(1 for t in tasks if t.get("status") == "success")
                        total = len(tasks)
                        # å¦‚æœå…¨éƒ¨æˆåŠŸï¼Œä¹Ÿç®—ç¿»è¯‘å®Œæˆ
                        if total > 0 and success_count == total:
                            status = "ç¿»è¯‘å®Œæˆ"
                        else:
                            status = f"ç¿»è¯‘ä¸­ ({success_count}/{total})"
                except:
                    status = "å·²æå–" # è¯»å–å¤±è´¥å›é€€
            # 4. æœ€æ¬¡ï¼šåªæœ‰æå–å‡ºçš„ä¸Šä¸‹æ–‡
            elif os.path.exists(context_path):
                status = "å·²æå–"
            
            papers.append({
                "filename": f,
                "raw_name": raw_name,
                "status": status
            })
    return papers

# --- API: è·å– PDF æŸä¸€é¡µçš„å›¾ç‰‡ (ç”¨äºå‰ç«¯ Canvas èƒŒæ™¯) ---
@app.get("/api/pdf/{filename}/page/{page_idx}")
def get_pdf_page_image(filename: str, page_idx: int):
    pdf_path = os.path.join(CONFIG["pdf_dir"], filename)
    if not os.path.exists(pdf_path):
        raise HTTPException(404, "PDF not found")
    
    doc = fitz.open(pdf_path)
    if page_idx < 0 or page_idx >= len(doc):
        raise HTTPException(400, "Page index out of range")
        
    page = doc[page_idx]
    # 2å€ç¼©æ”¾ä»¥ä¿è¯å‰ç«¯æ¸…æ™°åº¦
    pix = page.get_pixmap(matrix=fitz.Matrix(2, 2)) 
    img_data = pix.tobytes("png")
    base64_str = base64.b64encode(img_data).decode('utf-8')
    
    return {
        "image": f"data:image/png;base64,{base64_str}",
        "width": page.rect.width,
        "height": page.rect.height,
        "total_pages": len(doc)
    }

# --- API: åŠ è½½/ä¿å­˜ å¸ƒå±€ä¿¡æ¯ (JSON) ---
@app.get("/api/layout/{filename}")
def load_layout(filename: str):
    raw_name = wf.sanitize_filename(filename)
    json_path = os.path.join(CONFIG["extract_dir"], raw_name, "layout_config.json")
    if os.path.exists(json_path):
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

@app.post("/api/layout/save")
def save_layout(req: SaveLayoutRequest):
    raw_name = wf.sanitize_filename(req.filename)
    target_dir = os.path.join(CONFIG["extract_dir"], raw_name)
    os.makedirs(target_dir, exist_ok=True)
    json_path = os.path.join(target_dir, "layout_config.json")
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(req.layout_data, f, ensure_ascii=False, indent=2)
    return {"status": "success"}

# [æ–°å¢] API: è·å–æå–åçš„ä»»åŠ¡åˆ—è¡¨ (Step 2 ä½¿ç”¨)
@app.get("/api/extract/{filename}")
def get_extract_data(filename: str):
    raw_name = wf.sanitize_filename(filename)
    
    # 1. å°è¯•è¯»å–ç°æœ‰çš„ç¼“å­˜ (è¿›åº¦ä¼˜å…ˆ)
    cache_path = os.path.join(CONFIG["llm_dir"], f"{raw_name}_llm_cache.json")
    if os.path.exists(cache_path):
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # è¿”å›å®Œæ•´ç»“æ„ï¼Œä»¥ä¾¿å‰ç«¯è·å– ref_map
                return data 
        except Exception as e:
            print(f"Cache read error: {e}")
            # å¦‚æœç¼“å­˜åäº†ï¼Œç»§ç»­å‘ä¸‹å°è¯•é‡æ–°æ„å»º
            
    # 2. å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œå°è¯•ä» Context å®æ—¶æ„å»º (å…œåº•æ–¹æ¡ˆ)
    context_path = os.path.join(CONFIG["extract_dir"], f"{raw_name}_context.txt")
    if os.path.exists(context_path):
        try:
            with open(context_path, 'r', encoding='utf-8') as f:
                content = f.read()
            # å®æ—¶æ„å»ºä»»åŠ¡åˆ—è¡¨ (ä¸ä¿å­˜æ–‡ä»¶ï¼Œä»…ç”¨äºå‰ç«¯å±•ç¤º)
            tasks, ref_map_str, _ = wf.build_initial_tasks(content)
            # æ„é€ ä¸€ä¸ªä¸´æ—¶çš„å…¼å®¹å¯¹è±¡è¿”å›
            return {
                "tasks": tasks,
                "ref_map": ref_map_str,
                "is_temp": True
            }
        except Exception as e:
            raise HTTPException(500, f"Failed to build from context: {str(e)}")
            
    # 3. éƒ½æ²¡æœ‰ï¼Œè¯´æ˜ Step 1 æ²¡è·‘å®Œ
    raise HTTPException(404, "Data not found. Please run Step 1 Extraction first.")
    
# --- API: è§¦å‘å·¥ä½œæµ ---
def _run_extract_task(pdf_path, extract_dir, vis_dir):
    # è°ƒç”¨ä¿®æ”¹åçš„ utilsï¼Œskip_ui=True
    wf.extract_text_and_save_assets_smart(pdf_path, extract_dir, vis_dir, skip_ui=True)

@app.post("/api/workflow/extract/{filename}")
def trigger_extract(filename: str, background_tasks: BackgroundTasks):
    pdf_path = os.path.join(CONFIG["pdf_dir"], filename)
    # åå°è¿è¡Œï¼Œé¿å…é˜»å¡ç½‘é¡µ
    background_tasks.add_task(_run_extract_task, pdf_path, CONFIG["extract_dir"], CONFIG["vis_dir"])
    return {"status": "started", "msg": "åå°æå–ä»»åŠ¡å·²å¯åŠ¨"}

def _run_translate_task(context_path, result_path, cache_path):
    wf.run_smart_analysis(context_path, result_path, cache_path=cache_path)

@app.post("/api/workflow/translate/{filename}")
def trigger_translate(filename: str, background_tasks: BackgroundTasks):
    raw_name = wf.sanitize_filename(filename)
    ctx_path = os.path.join(CONFIG["extract_dir"], f"{raw_name}_context.txt")
    res_path = os.path.join(CONFIG["llm_dir"], f"{raw_name}_llm_result.txt")
    cache_path = os.path.join(CONFIG["llm_dir"], f"{raw_name}_llm_cache.json")
    
    background_tasks.add_task(_run_translate_task, ctx_path, res_path, cache_path)
    return {"status": "started", "msg": "LLM ç¿»è¯‘ä»»åŠ¡å·²å¯åŠ¨"}

async def event_generator(raw_name):
    """SSE ç”Ÿæˆå™¨ï¼šç›‘å¬ Cache æ–‡ä»¶å˜åŒ–å¹¶æ¨é€"""
    cache_path = os.path.join(CONFIG["llm_dir"], f"{raw_name}_llm_cache.json")
    last_mod_time = 0
    
    while True:
        if os.path.exists(cache_path):
            try:
                # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´ï¼Œæœ‰å˜åŒ–æ‰è¯»å–
                current_mod_time = os.path.getmtime(cache_path)
                if current_mod_time > last_mod_time:
                    last_mod_time = current_mod_time
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        tasks = data.get("tasks", [])
                        # æ¨é€ JSON å­—ç¬¦ä¸²ï¼Œæ ¼å¼å¿…é¡»æ˜¯ 'data: ...\n\n'
                        yield f"data: {json.dumps(tasks)}\n\n"
                        
                        # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å®Œæˆï¼Œå¦‚æœæ˜¯ï¼Œå‘é€ç»“æŸä¿¡å·
                        if tasks and all(t.get("status") == "success" for t in tasks):
                            yield "event: close\ndata: done\n\n"
                            break
            except Exception as e:
                print(f"SSE Error: {e}")
        
        # æ¯ 1 ç§’æ£€æŸ¥ä¸€æ¬¡æ–‡ä»¶ï¼ˆè¿™æ˜¯åç«¯æ£€æŸ¥ï¼Œæ¯” HTTP è¯·æ±‚è½»é‡å¾—å¤šï¼‰
        await asyncio.sleep(1)

@app.get("/api/stream/translation/{filename}")
async def stream_translation_progress(filename: str):
    raw_name = wf.sanitize_filename(filename)
    return StreamingResponse(event_generator(raw_name), media_type="text/event-stream")

@app.post("/api/workflow/generate_report/{filename}")
def generate_report(filename: str):
    raw_name = wf.sanitize_filename(filename)
    res_path = os.path.join(CONFIG["llm_dir"], f"{raw_name}_llm_result.txt")
    vis_base = os.path.join(CONFIG["vis_dir"], raw_name)
    
    try:
        report_path = wf.generate_html_report(res_path, vis_base)
        # è¿”å›ç›¸å¯¹è·¯å¾„ä¾›å‰ç«¯ iframe è®¿é—®
        rel_path = f"/output/{raw_name}/{raw_name}_Report.html"
        return {"status": "success", "url": rel_path}
    except Exception as e:
        return {"status": "error", "msg": str(e)}

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ Web æœåŠ¡: http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)