import os
import re
import time
import shutil
import platform
import fitz  # PyMuPDF
import json      # æ–°å¢
import hashlib   # æ–°å¢
import tkinter as tk
from tkinter import messagebox, font, ttk
from PIL import Image, ImageTk, ImageOps
from openai import OpenAI # ä½¿ç”¨ OpenAI å…¼å®¹åº“

# --- é…ç½®å¸¸é‡ ---
MAX_CHUNK_CHARS = 1000
TIMEOUT_MS = 600000
MAX_RETRIES = 3

# ==============================================================================
# 1. å®šä¹‰å¤šåœºæ™¯ä¸“ç”¨ Prompt
# ==============================================================================

# --- åœºæ™¯ A: å…ƒæ•°æ®ä¸“ç”¨ (å¼ºæ ¼å¼çº¦æŸ) ---
SYSTEM_PROMPT_META = """
ä½ æ˜¯ä¸€ä¸ªå…ƒæ•°æ®è§£æå™¨ã€‚è¯·å°†è¾“å…¥çš„è®ºæ–‡ã€æ ‡é¢˜ã€‘å’Œã€ä½œè€…ä¿¡æ¯ã€‘ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚

**æ ¸å¿ƒè§„åˆ™ (Strict Rules):**
1. **è¾“å…¥æ ¼å¼**: 
   - `[[META_TITLE: ...]]` -> è®ºæ–‡æ ‡é¢˜
   - `[[META_AUTHOR: ...]]` -> ä½œè€…/æœºæ„ä¿¡æ¯
2. **è¾“å‡ºæ ¼å¼ (å¿…é¡»ä¸¥æ ¼éµå®ˆ XML)**:
   - <meta_title>ä¸­æ–‡æ ‡é¢˜</meta_title>
   - <meta_author>ä¸­æ–‡ä½œè€…/æœºæ„</meta_author>
3. **ç¦æ­¢**: ç»å¯¹ä¸è¦è¾“å‡ºåŸæ–‡ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼Œä¸è¦è¾“å‡º markdown ä»£ç å—ã€‚
4. **äººåå¤„ç†**: å¦‚æœä½œè€…æ˜¯å¤–å›½äººåï¼Œå»ºè®®ä¿ç•™è‹±æ–‡æˆ–ä½¿ç”¨é€šç”¨éŸ³è¯‘ï¼›æœºæ„åè¯·ç¿»è¯‘ã€‚
"""

# --- åœºæ™¯ B: æ­£æ–‡ä¸“ç”¨ (å­¦æœ¯é£æ ¼ + å¼•ç”¨å¤„ç†) ---
SYSTEM_PROMPT_BODY = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡ç¿»è¯‘å¼•æ“ã€‚è¯·å°†è¾“å…¥çš„å­¦æœ¯æ®µè½ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚
**è¾“å…¥èµ„æºæ˜ å°„è¡¨ (Ref Map):**
{ref_map_str}

**æ ¸å¿ƒè§„åˆ™:**
1. **é£æ ¼**: ä¿æŒå­¦æœ¯è®ºæ–‡çš„ä¸¥è°¨ã€å®¢è§‚ã€é€»è¾‘æ€§ã€‚
2. **ç»“æ„**: 
   - ç« èŠ‚æ ‡é¢˜ -> <header>è¯‘æ–‡</header>
   - æ­£æ–‡æ®µè½ -> <p>è¯‘æ–‡</p>
3. **å¼•ç”¨**: é‡åˆ°æ–‡ä¸­å¼•ç”¨ (å¦‚ "Figure 1", "Eq. 2")ï¼Œå¿…é¡»æ ¹æ® Map æ ¼å¼åŒ–ä¸º `[[LINK: ID|åŸæ–‡]]`ã€‚
   - ç¤ºä¾‹: "As shown in Fig. 1" -> "å¦‚å›¾ [[LINK: Figure_1|Fig. 1]] æ‰€ç¤º"
4. **ç¦æ­¢**: ç»å¯¹ä¸è¦è¾“å‡º <src> åŸæ–‡æ ‡ç­¾ã€‚åªè¾“å‡ºè¯‘æ–‡ã€‚
5. **ä¿ç•™**: è¯·ä¿ç•™åŸæ–‡ä¸­çš„å¼•ç”¨æ ‡è®°ï¼ˆå¦‚ [1], [1-5]ï¼‰ï¼Œä¸è¦ä¿®æ”¹å…¶æ ¼å¼ã€‚
"""

# --- åœºæ™¯ C: èµ„æºè¯´æ˜ä¸“ç”¨ (å›¾è¡¨/ç®—æ³•æè¿°) ---
SYSTEM_PROMPT_ASSET = """
ä½ æ˜¯ä¸€ä¸ªå›¾è¡¨è¯´æ˜ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·ç¿»è¯‘ä»¥ä¸‹å›¾è¡¨ã€ç®—æ³•æˆ–å…¬å¼çš„æ ‡é¢˜ä¸è¯´æ˜ã€‚

**è¾“å…¥èµ„æºæ˜ å°„è¡¨ (Ref Map):**
{ref_map_str}

**æ ¸å¿ƒè§„åˆ™:**
1. **è¾“å…¥æ ¼å¼**: `[[ASSET_CAPTION: ID | Text...]]`
2. **è¾“å‡ºæ ¼å¼**: <asset id="ID">ä¸­æ–‡è¯‘æ–‡</asset>
3. **å¤„ç†**: 
   - ä¿æŒç®€æ´ï¼Œå‡†ç¡®æè¿°å›¾è¡¨å«ä¹‰ã€‚
   - é‡åˆ°å ä½ç¬¦ `[[ASSET_PLACEHOLDER:...]]`ï¼Œè¯·ç›´æ¥å¿½ç•¥æˆ–è¾“å‡ºç©ºæ ‡ç­¾ã€‚
"""

def sanitize_filename(filename: str) -> str:
    if not filename: return "untitled"
    name = os.path.splitext(os.path.basename(filename))[0]
    return re.sub(r'[\\/*?:"<>|]', '', name).replace('\n','').strip()

def is_box_in_rect(box, rect, threshold=0.5):
    bx0, by0, bx1, by1 = box
    rx0, ry0, rx1, ry1 = rect
    ix0 = max(bx0, rx0); iy0 = max(by0, ry0)
    ix1 = min(bx1, rx1); iy1 = min(by1, ry1)
    if ix1 > ix0 and iy1 > iy0:
        inter = (ix1 - ix0) * (iy1 - iy0)
        b_area = (bx1 - bx0) * (by1 - by0)
        if b_area > 0 and inter / b_area > threshold: return True
    return False

def get_optimal_font(root):
    system = platform.system()
    available = set(font.families(root))
    if system == "Windows": candidates = ["Microsoft YaHei UI", "SimHei"]
    elif system == "Darwin": candidates = ["PingFang SC", "Heiti SC"]
    else: candidates = ["Noto Sans CJK SC", "WenQuanYi Micro Hei"]
    for f in candidates:
        if f in available: return f
    return "Helvetica"

# --- äº¤äº’å¼ç¼–è¾‘å™¨ ---
class LayoutEditor:
    def __init__(self, doc, initial_data):
        self.doc = doc
        self.data = initial_data 
        self.page_count = len(doc)
        self.current_page = 0
        
        self.root = tk.Tk()
        self.ui_font = get_optimal_font(self.root)
        self.root.title(f"PDF ç»“æ„åŒ–æ ¡å¯¹ (æ–°å¢: 5-æ ‡é¢˜ 6-ä½œè€… 7-é®ç½©)")
        
        if platform.system() == "Windows":
            self.root.state('zoomed')
        else:
            w = self.root.winfo_screenwidth()
            h = self.root.winfo_screenheight()
            self.root.geometry(f"{w}x{h}+0+0")

        self.current_tool_type = tk.StringVar(value="Figure") 
        self.current_id = tk.IntVar(value=1)
        self.current_role = tk.StringVar(value="Body") 
        
        # é¢œè‰²å®šä¹‰
        self.colors = {
            "Figure": "#e74c3c",    # çº¢
            "Table": "#3498db",     # è“
            "Equation": "#27ae60",  # ç»¿
            "Algorithm": "#9b59b6", # ç´«
            "Title": "#d35400",     # æ·±æ©™ (æ ‡é¢˜)
            "Author": "#1abc9c",    # é’è‰² (ä½œè€…)
            "Mask": "#7f8c8d",      # ç°è‰² (é®ç½©)
            "ContentArea": "#f1c40f" # é»„
        }

        self.main_paned = tk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        self.main_paned.pack(fill=tk.BOTH, expand=True)

        self.canvas_frame = tk.Frame(self.main_paned, bg="#555")
        self.sidebar_frame = tk.Frame(self.main_paned, bg="#f0f0f0", width=340)
        
        self.main_paned.add(self.canvas_frame, stretch="always")
        self.main_paned.add(self.sidebar_frame, stretch="never")

        self.setup_sidebar()

        self.v_scroll = tk.Scrollbar(self.canvas_frame, orient=tk.VERTICAL)
        self.h_scroll = tk.Scrollbar(self.canvas_frame, orient=tk.HORIZONTAL)
        self.canvas = tk.Canvas(self.canvas_frame, bg="#555",
                                yscrollcommand=self.v_scroll.set, xscrollcommand=self.h_scroll.set)
        self.v_scroll.config(command=self.canvas.yview)
        self.h_scroll.config(command=self.canvas.xview)
        
        self.v_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        self.h_scroll.pack(side=tk.BOTTOM, fill=tk.X)
        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        self.canvas.bind("<ButtonPress-1>", self.on_mouse_down)
        self.canvas.bind("<B1-Motion>", self.on_mouse_drag)
        self.canvas.bind("<ButtonRelease-1>", self.on_mouse_up)
        self.canvas.bind("<Button-3>", self.on_right_click)
        self.root.bind("<Key>", self.on_key_press)

        self.scale = 1.5 
        self.rect_id_map = {}
        self.start_x = None; self.start_y = None; self.current_rect_id = None
        
        self.update_id_suggestion()
        self.load_page()
        self.root.mainloop()

    def setup_sidebar(self):
        f_title = (self.ui_font, 14, "bold")
        f_norm = (self.ui_font, 12)
        f_bold = (self.ui_font, 12, "bold")
        
        p = 10
        tk.Label(self.sidebar_frame, text="å·¥å…·ç®± (Toolbox)", font=f_title, bg="#f0f0f0").pack(pady=(15, 10))
        
        # 1. Type
        type_frame = tk.LabelFrame(self.sidebar_frame, text="1. å…ƒç´ ç±»å‹", font=f_bold, bg="#f0f0f0")
        type_frame.pack(fill=tk.X, padx=p, pady=5)
        
        # åˆ†ç»„æ˜¾ç¤º
        types_group1 = [
            ("å›¾ (Figure) - [1]", "Figure"), 
            ("è¡¨ (Table) - [2]", "Table"), 
            ("å¼ (Equation) - [3]", "Equation"), 
            ("ç®— (Algorithm) - [4]", "Algorithm")
        ]
        types_group2 = [
            ("æ ‡é¢˜ (Title) - [5]", "Title"),
            ("ä½œè€… (Author) - [6]", "Author"),
            ("é®ç½© (Mask) - [7]", "Mask")
        ]
        
        for text, val in types_group1:
            tk.Radiobutton(type_frame, text=text, variable=self.current_tool_type, value=val, 
                           command=self.update_id_suggestion, font=f_norm, bg="#f0f0f0", anchor="w").pack(fill=tk.X, padx=5)
        
        ttk.Separator(type_frame, orient='horizontal').pack(fill='x', padx=5, pady=5)
        
        for text, val in types_group2:
            tk.Radiobutton(type_frame, text=text, variable=self.current_tool_type, value=val, 
                           command=self.update_id_suggestion, font=f_norm, bg="#f0f0f0", anchor="w").pack(fill=tk.X, padx=5)
        
        ttk.Separator(type_frame, orient='horizontal').pack(fill='x', padx=5, pady=5)
        tk.Radiobutton(type_frame, text="æ­£æ–‡èŒƒå›´ - [0]", variable=self.current_tool_type, value="ContentArea", 
                        command=self.update_id_suggestion, font=f_norm, bg="#f0f0f0", anchor="w").pack(fill=tk.X, padx=5)

        # 2. Props
        prop_frame = tk.LabelFrame(self.sidebar_frame, text="2. å±æ€§è®¾å®š", font=f_bold, bg="#f0f0f0")
        prop_frame.pack(fill=tk.X, padx=p, pady=5)
        
        row1 = tk.Frame(prop_frame, bg="#f0f0f0")
        row1.pack(fill=tk.X, padx=5, pady=5)
        tk.Label(row1, text="ç¼–å· (ID):", font=f_norm, bg="#f0f0f0").pack(side=tk.LEFT)
        tk.Button(row1, text="-", command=lambda: self.adj_id(-1), font=f_bold, width=3).pack(side=tk.LEFT, padx=5)
        self.id_entry = tk.Entry(row1, textvariable=self.current_id, width=5, font=f_norm, justify='center')
        self.id_entry.pack(side=tk.LEFT)
        tk.Button(row1, text="+", command=lambda: self.adj_id(1), font=f_bold, width=3).pack(side=tk.LEFT, padx=5)
        
        tk.Label(prop_frame, text="è§’è‰² (Role):", font=f_norm, bg="#f0f0f0").pack(anchor="w", padx=5, pady=(5,0))
        tk.Radiobutton(prop_frame, text="å†…å®¹æˆªå›¾ (Body)", variable=self.current_role, value="Body", font=f_norm, bg="#f0f0f0").pack(anchor="w", padx=15)
        tk.Radiobutton(prop_frame, text="æ ‡é¢˜æ–‡æœ¬ (Caption)", variable=self.current_role, value="Caption", font=f_norm, bg="#f0f0f0").pack(anchor="w", padx=15)

        # 3. List
        list_frame = tk.LabelFrame(self.sidebar_frame, text="å½“å‰é¡µåˆ—è¡¨ (Delåˆ é™¤)", font=f_bold, bg="#f0f0f0")
        list_frame.pack(fill=tk.BOTH, expand=True, padx=p, pady=5)
        self.item_listbox = tk.Listbox(list_frame, bg="white", height=10, font=(self.ui_font, 11))
        self.item_listbox.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.item_listbox.bind("<Delete>", self.delete_selected_list_item)

        # 4. Nav
        nav_frame = tk.Frame(self.sidebar_frame, bg="#f0f0f0")
        nav_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=p, pady=20)
        tk.Button(nav_frame, text="< ä¸Šä¸€é¡µ", command=self.prev_page, font=f_norm).pack(side=tk.LEFT)
        self.btn_next = tk.Button(nav_frame, text="ä¸‹ä¸€é¡µ >", command=self.next_page, font=f_bold, bg="#2ecc71", fg="white")
        self.btn_next.pack(side=tk.RIGHT)

    def adj_id(self, delta):
        val = self.current_id.get() + delta
        if val < 1: val = 1
        self.current_id.set(val)

    def set_tool(self, tool_type):
        self.current_tool_type.set(tool_type)
        self.update_id_suggestion()

    def update_id_suggestion(self):
        ctype = self.current_tool_type.get()
        if ctype in ["ContentArea", "Mask", "Title", "Author"]: return
        
        max_id = 0
        for p_idx in self.data:
            for item in self.data[p_idx]:
                if item['type'] == ctype:
                    max_id = max(max_id, item.get('id', 0))
        self.current_id.set(max_id + 1)
        self.current_role.set("Body")

    def load_page(self):
        self.canvas.delete("all")
        self.rect_id_map = {}
        self.item_listbox.delete(0, tk.END)
        
        page = self.doc[self.current_page]
        pix = page.get_pixmap(matrix=fitz.Matrix(self.scale, self.scale))
        self.tk_img = ImageTk.PhotoImage(Image.frombytes("RGB", [pix.width, pix.height], pix.samples))
        
        self.canvas.config(scrollregion=(0, 0, pix.width, pix.height))
        self.canvas.create_image(0, 0, anchor=tk.NW, image=self.tk_img)
        
        self.btn_next.config(text="ç”Ÿæˆç»“æœ (Finish)" if self.current_page == self.page_count - 1 else "ä¸‹ä¸€é¡µ >")
        
        if self.current_page in self.data:
            for idx, item in enumerate(self.data[self.current_page]):
                self.draw_box(item, idx)
                desc = f"[{item['type']}]"
                if item['type'] not in ["ContentArea", "Mask", "Title", "Author"]:
                    desc += f" {item['id']} - {item['role']}"
                self.item_listbox.insert(tk.END, desc)

    def draw_box(self, item, idx):
        r = item['rect']
        x0, y0, x1, y1 = r.x0*self.scale, r.y0*self.scale, r.x1*self.scale, r.y1*self.scale
        color = self.colors.get(item['type'], "black")
        
        dash = (4, 4) if item.get('role') == 'Caption' else None
        width = 3 if item['type'] == 'ContentArea' else 2
        stipple = 'gray50' if item['type'] == 'Mask' else '' # é®ç½©åŠ é˜´å½±
        
        rect_id = self.canvas.create_rectangle(x0, y0, x1, y1, outline=color, width=width, dash=dash, stipple=stipple, tags="box")
        
        label_txt = item['type']
        if item['type'] not in ['ContentArea', 'Mask', 'Title', 'Author']:
            label_txt += f" {item['id']} ({item['role'][0]})"
        
        bg_id = self.canvas.create_rectangle(x0, y0-20, x0+len(label_txt)*9, y0, fill=color, outline=color, tags="box")
        txt_id = self.canvas.create_text(x0+2, y0-10, text=label_txt, anchor=tk.W, fill="white", font=("Arial", 10, "bold"), tags="box")
        
        self.rect_id_map[rect_id] = idx
        self.rect_id_map[bg_id] = idx
        self.rect_id_map[txt_id] = idx

    def on_mouse_down(self, event):
        self.start_x = self.canvas.canvasx(event.x)
        self.start_y = self.canvas.canvasy(event.y)
        color = self.colors.get(self.current_tool_type.get(), "black")
        self.current_rect_id = self.canvas.create_rectangle(self.start_x, self.start_y, self.start_x, self.start_y, outline=color, width=2, dash=(2,2))

    def on_mouse_drag(self, event):
        self.canvas.coords(self.current_rect_id, self.start_x, self.start_y, self.canvas.canvasx(event.x), self.canvas.canvasy(event.y))

    def on_mouse_up(self, event):
        x0, x1 = sorted([self.start_x, self.canvas.canvasx(event.x)])
        y0, y1 = sorted([self.start_y, self.canvas.canvasy(event.y)])
        self.canvas.delete(self.current_rect_id)
        
        if x1 - x0 < 10 or y1 - y0 < 10: return
        
        pdf_rect = fitz.Rect(x0/self.scale, y0/self.scale, x1/self.scale, y1/self.scale)
        
        new_item = {
            'rect': pdf_rect,
            'type': self.current_tool_type.get(),
            'id': self.current_id.get(),
            'role': self.current_role.get()
        }
        
        if self.current_page not in self.data: self.data[self.current_page] = []
        if new_item['type'] == 'ContentArea':
             self.data[self.current_page] = [x for x in self.data[self.current_page] if x['type'] != 'ContentArea']

        self.data[self.current_page].append(new_item)
        
        # è‡ªåŠ¨åˆ‡æ¢ role é€»è¾‘
        no_caption_types = ['ContentArea', 'Equation', 'Mask', 'Title', 'Author']
        if new_item['type'] not in no_caption_types and new_item['role'] == 'Body':
            self.current_role.set("Caption")
        
        self.load_page()

    def on_right_click(self, event):
        x, y = self.canvas.canvasx(event.x), self.canvas.canvasy(event.y)
        items = self.canvas.find_overlapping(x-2, y-2, x+2, y+2)
        for item_id in items:
            if item_id in self.rect_id_map:
                idx = self.rect_id_map[item_id]
                del self.data[self.current_page][idx]
                self.load_page()
                break

    def delete_selected_list_item(self, event):
        sel = self.item_listbox.curselection()
        if sel:
            idx = sel[0]
            del self.data[self.current_page][idx]
            self.load_page()

    def on_key_press(self, event):
        k = event.keysym
        if k == '1': self.set_tool("Figure")
        elif k == '2': self.set_tool("Table")
        elif k == '3': self.set_tool("Equation")
        elif k == '4': self.set_tool("Algorithm") 
        elif k == '5': self.set_tool("Title")   # æ–°å¢
        elif k == '6': self.set_tool("Author")  # æ–°å¢
        elif k == '7': self.set_tool("Mask")    # æ–°å¢
        elif k == '0': self.set_tool("ContentArea")
        elif k in ['space', 'Return', 'Right']: self.next_page()
        elif k in ['BackSpace', 'Left']: self.prev_page()

    def next_page(self):
        curr_content = next((x for x in self.data.get(self.current_page, []) if x['type'] == 'ContentArea'), None)
        next_idx = self.current_page + 1
        
        if next_idx < self.page_count:
            if next_idx not in self.data: self.data[next_idx] = []
            
            if curr_content:
                if self.doc[self.current_page].rect == self.doc[next_idx].rect:
                     self.data[next_idx] = [x for x in self.data[next_idx] if x['type'] != 'ContentArea']
                     self.data[next_idx].insert(0, curr_content.copy())

            self.current_page += 1
            self.load_page()
        else:
            if messagebox.askyesno("å®Œæˆ", "ç¡®è®¤å®Œæˆæ‰€æœ‰æ ¡å¯¹ï¼Ÿ"):
                self.root.destroy()

    def prev_page(self):
        if self.current_page > 0:
            self.current_page -= 1
            self.load_page()

def split_long_buffer_safely(text, max_len):
    """
    å°†è¶…é•¿æ–‡æœ¬æ‹†åˆ†ä¸ºå¤šä¸ªç‰‡æ®µï¼Œç¡®ä¿æ‹†åˆ†ç‚¹åœ¨å¥å­ç»“æŸå¤„ã€‚
    """
    if len(text) <= max_len:
        return [text]
    
    # æ­£åˆ™è§£é‡Šï¼š
    # (?<=[.?!;]) : å‰é¢å¿…é¡»æ˜¯å¥å·ã€é—®å·ã€æ„Ÿå¹å·æˆ–åˆ†å·
    # \s+         : ä¸­é—´æœ‰ç©ºæ ¼
    # (?=[A-Z0-9]): åé¢å¿…é¡»æ˜¯å¤§å†™å­—æ¯æˆ–æ•°å­— (é˜²æ­¢åˆ‡æ–­ e.g. æˆ– Fig. 1)
    # æ³¨æ„ï¼šè¿™åªæ˜¯ä¸€ä¸ªå¯å‘å¼è§„åˆ™ï¼Œèƒ½è¦†ç›–ç»å¤§å¤šæ•°æƒ…å†µ
    sentences = re.split(r'(?<=[.?!;])\s+(?=[A-Z0-9])', text)
    
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°å¥å­ä¼šè¶…é•¿ï¼Œä¸”å½“å‰å—ä¸ä¸ºç©º -> å°åŒ…
        if len(current_chunk) + len(sentence) > max_len and current_chunk:
            chunks.append(current_chunk)
            current_chunk = sentence
        else:
            # æ‹¼æ¥
            if current_chunk:
                current_chunk += " " + sentence
            else:
                current_chunk = sentence
                
    if current_chunk:
        chunks.append(current_chunk)
        
    return chunks

# --- è¾…åŠ©å‡½æ•°ï¼šæ®µè½æµå¤„ç† (å«é•¿éš¾å¥æ‹†åˆ†) ---
def smart_merge_paragraphs(blocks, max_split_len=500):
    """
    blocks: åŸå§‹æ–‡æœ¬å—æµ
    max_split_len: å•ä¸ªæ®µè½æœ€å¤§å­—ç¬¦æ•°ï¼Œè¶…è¿‡åˆ™å°è¯•åœ¨å¥å·å¤„å¼ºè¡Œæ‹†åˆ†
    """
    if not blocks: return []
    merged = []
    buffer = ""
    terminals = ('.', '?', '!', ':', ';', 'ã€‚', 'ï¼Ÿ', 'ï¼', 'ï¼š', 'ï¼›')
    hard_boundary_pattern = re.compile(r'^\[\[(HEADER|ASSET_|META_).*?\]\]')

    for block in blocks:
        block = block.strip()
        if not block: continue
        
        # 1. é‡åˆ°ç¡¬æ€§è¾¹ç•Œ -> å¼ºåˆ¶åˆ·æ–° Buffer
        if hard_boundary_pattern.match(block):
            if buffer:
                # --- æ”¹åŠ¨ç‚¹ï¼šFlush æ—¶æ£€æŸ¥é•¿åº¦å¹¶æ‹†åˆ† ---
                merged.extend(split_long_buffer_safely(buffer, max_split_len))
                buffer = ""
            merged.append(block)
            continue
        
        # 2. åˆå§‹åŒ– Buffer
        if not buffer:
            buffer = block
            continue
            
        # 3. é€»è¾‘åˆ¤å®š
        prev_end_char = buffer[-1] if buffer else ""
        
        # æƒ…å†µ A: è¿å­—ç¬¦ä¿®å¤
        if prev_end_char == '-':
            buffer = buffer[:-1] + block
        # æƒ…å†µ B: å¥å­æœªç»“æŸ (éç»ˆæ­¢ç¬¦ç»“å°¾ OR ä¸‹ä¸€æ®µå°å†™å¼€å¤´)
        elif (not buffer.endswith(terminals)) or (block[0].islower()):
            buffer = buffer + " " + block
        # æƒ…å†µ C: æ­£å¸¸çš„æ®µè½ç»“æŸ (å¥å·ç»“å°¾ + å¤§å†™å¼€å¤´)
        else:
            # æ—¢ç„¶æ®µè½ç»“æŸäº†ï¼Œå°± Flush è¿› merged
            # --- æ”¹åŠ¨ç‚¹ï¼šFlush æ—¶æ£€æŸ¥é•¿åº¦å¹¶æ‹†åˆ† ---
            merged.extend(split_long_buffer_safely(buffer, max_split_len))
            buffer = block # æ–°çš„ block å¼€å¯æ–°çš„ buffer

    # å¤„ç†æ®‹ç•™
    if buffer:
        merged.extend(split_long_buffer_safely(buffer, max_split_len))
    
    return merged

# --- æ ¸å¿ƒæå–é€»è¾‘ ---
def extract_text_and_save_assets_smart(pdf_path: str, raw_text_dir: str, vis_output_root: str) -> tuple[str, str, str, int]:
    if not os.path.exists(pdf_path): raise FileNotFoundError(f"PDF missing: {pdf_path}")
    
    clean_name = sanitize_filename(pdf_path)
    os.makedirs(raw_text_dir, exist_ok=True)
    txt_path = os.path.join(raw_text_dir, f"{clean_name}_context.txt")
    
    vis_dir = os.path.join(vis_output_root, clean_name)
    assets_dir = os.path.join(vis_dir, "assets")
    if os.path.exists(assets_dir): shutil.rmtree(assets_dir)
    os.makedirs(assets_dir, exist_ok=True)

    doc = fitz.open(pdf_path)
    
    # 1. åˆå§‹åŒ–
    init_data = {}
    for i, page in enumerate(doc):
        w, h = page.rect.width, page.rect.height
        init_data[i] = [{'rect': fitz.Rect(0, h*0.08, w, h*0.92), 'type': 'ContentArea'}]

    # 2. äº¤äº’æ ¡å¯¹
    editor = LayoutEditor(doc, init_data)
    verified_data = editor.data

    # 3. èµ„æºèšåˆ & å…ƒæ•°æ®æå–
    print("ğŸ§© æ­£åœ¨å¤„ç†å…ƒæ•°æ®ä¸èµ„æº...")
    assets_agg = {}
    meta_info_blocks = [] # å­˜å‚¨ Title å’Œ Author
    
    for p_idx in range(len(doc)):
        page = doc[p_idx]
        items = verified_data.get(p_idx, [])
        
        for item in items:
            # ç‰¹æ®Šå¤„ç† Title å’Œ Author
            if item['type'] == 'Title':
                txt = page.get_text("text", clip=item['rect']).strip().replace('\n', ' ')
                meta_info_blocks.append(f"[[META_TITLE: {txt}]]")
                continue
            if item['type'] == 'Author':
                txt = page.get_text("text", clip=item['rect']).strip().replace('\n', ' ')
                meta_info_blocks.append(f"[[META_AUTHOR: {txt}]]")
                continue
            
            # å…¶ä»–æ­£å¸¸èµ„æº
            if item['type'] in ['ContentArea', 'Mask']: continue
            
            key = f"{item['type']}_{item['id']}" 
            if key not in assets_agg: assets_agg[key] = {'bodies': [], 'captions': [], 'rects': []}
            assets_agg[key]['rects'].append(item['rect']) 
            
            if item['role'] == 'Body':
                pix = page.get_pixmap(clip=item['rect'], matrix=fitz.Matrix(3,3))
                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                assets_agg[key]['bodies'].append(img)
            elif item['role'] == 'Caption':
                text = page.get_text("text", clip=item['rect']).strip().replace('\n', ' ')
                assets_agg[key]['captions'].append(text)

    # 4. Ref Map
    ref_map = [] 
    asset_count = 0
    final_asset_captions = {} 

    for key, data in assets_agg.items():
        if data['bodies']:
            widths, heights = zip(*(i.size for i in data['bodies']))
            total_h = sum(heights)
            max_w = max(widths)
            merged_img = Image.new('RGB', (max_w, total_h), (255, 255, 255))
            y_off = 0
            for img in data['bodies']:
                merged_img.paste(img, (0, y_off))
                y_off += img.height
            merged_img.save(os.path.join(assets_dir, f"{key}.png"))
            asset_count += 1
        
        full_caption = " ".join(data['captions'])
        final_asset_captions[key] = full_caption
        
        type_str, id_str = key.split('_')
        if type_str == "Figure": ref_map.append(f"Fig. {id_str} -> {key}")
        elif type_str == "Table": ref_map.append(f"Tab. {id_str} -> {key}")
        elif type_str == "Algorithm": ref_map.append(f"Alg. {id_str} -> {key}")
        elif type_str == "Equation": ref_map.append(f"Eq. {id_str} -> {key}")
        ref_map.append(f"{type_str} {id_str} -> {key}")

    ref_map_str = "\n".join(ref_map)

    # 5. æ­£æ–‡æå– (Masking é€»è¾‘ç”Ÿæ•ˆå¤„)
    print("ğŸ“ æå–æ­£æ–‡æ–‡æœ¬...")
    raw_paragraph_stream = [] 
    
    # å°†å…ƒæ•°æ®æ”¾åœ¨æœ€å‰é¢
    raw_paragraph_stream.extend(meta_info_blocks)
    
    header_pattern = re.compile(r'^(\d+(\.\d+)*\.?|[IVX]+\.|[A-Z]\.)\s+|^(Abstract|References|Introduction|Conclusion|Method)', re.IGNORECASE)

    for p_idx, page in enumerate(doc):
        ignore_rects = []
        page_items = verified_data.get(p_idx, [])
        content_rect = page.rect
        for item in page_items:
            if item['type'] == 'ContentArea': 
                content_rect = item['rect']
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šMask, Title, Author éƒ½ä½œä¸ºé®ç½©ï¼Œæ­£æ–‡ä¸æå– ---
            elif item['type'] in ['Mask', 'Title', 'Author']: 
                ignore_rects.append(item['rect'])
            # --------------------------------------------------------
            else: 
                ignore_rects.append(item['rect']) # å›¾è¡¨ç­‰èµ„æºåŒºåŸŸä¹Ÿä¸æå–

        raw_blocks = page.get_text("blocks", clip=content_rect)
        mid_x = (content_rect.x0 + content_rect.x1) / 2
        left_col, right_col = [], []
        for b in raw_blocks:
            if (b[0] + b[2]) / 2 < mid_x: left_col.append(b)
            else: right_col.append(b)
        left_col.sort(key=lambda b: (b[1], b[0]))
        right_col.sort(key=lambda b: (b[1], b[0]))
        sorted_blocks = left_col + right_col

        for b in sorted_blocks:
            bbox = fitz.Rect(b[:4])
            text = b[4].strip()
            
            is_asset = False
            for ir in ignore_rects:
                if is_box_in_rect(bbox, ir, 0.6): 
                    is_asset = True; break
            
            if not is_asset and text:
                text = re.sub(r'-\n', '', text)
                text = text.replace('\n', ' ')
                
                lines = text.split('\n')
                first_line = lines[0].strip()
                if header_pattern.match(first_line) and len(first_line) < 80:
                    raw_paragraph_stream.append(f"[[HEADER: {first_line}]]")
                    if len(lines) > 1: raw_paragraph_stream.append(" ".join(lines[1:]))
                else:
                    raw_paragraph_stream.append(text)

    # 6. åˆå¹¶
    merged_text_blocks = smart_merge_paragraphs(raw_paragraph_stream)

    # 7. Metadata
    assets_xml_snippets = []
    sorted_keys = sorted(assets_agg.keys(), key=lambda k: (k.split('_')[0], int(k.split('_')[1])))
    
    assets_xml_snippets.append("\n\n--- ASSETS METADATA ---\n")
    for key in sorted_keys:
        cap = final_asset_captions[key]
        if cap:
            assets_xml_snippets.append(f"[[ASSET_CAPTION: {key} | {cap}]]")
        else:
            assets_xml_snippets.append(f"[[ASSET_PLACEHOLDER: {key}]]")
    
    final_content = "\n\n".join(merged_text_blocks) + "\n\n" + "\n".join(assets_xml_snippets)
    
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(f"[[REF_MAP_START]]\n{ref_map_str}\n[[REF_MAP_END]]\n\n")
        f.write(final_content)

    return final_content, txt_path, vis_dir, asset_count

# --- è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—æ–‡æœ¬æŒ‡çº¹ ---
def compute_hash(text):
    return hashlib.md5(text.encode('utf-8')).hexdigest()

# --- è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½åˆ†ç¦»ï¼ˆä¿®å¤ Assets è¢«è¯¯åçš„é—®é¢˜ï¼‰---
# --- è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½åˆ†ç¦» (å››æ®µå¼åˆ‡åˆ†ï¼šMeta / Body / Assets / Refs) ---
def split_content_smart(text):
    """
    å°†æ–‡æœ¬åˆ‡åˆ†ä¸ºå››éƒ¨åˆ†ï¼Œç¡®ä¿æ¯ä¸€éƒ¨åˆ†éƒ½èƒ½è¢«ç‹¬ç«‹å¤„ç†ï¼š
    1. å…ƒæ•°æ® (Meta) -> å¿…é¡»å•ç‹¬ç¿»è¯‘ï¼Œé˜²æ­¢è¢«æ­£æ–‡åæ²¡
    2. èµ„æºè¯´æ˜ (Assets) -> å¿…é¡»ç¿»è¯‘
    3. å‚è€ƒæ–‡çŒ® (Refs) -> è·³è¿‡
    4. æ­£æ–‡ (Body) -> åˆ‡åˆ†ç¿»è¯‘
    """
    # --- 1. å‰¥ç¦» ASSETS METADATA (ä»å°¾éƒ¨æ‰¾) ---
    asset_marker = "--- ASSETS METADATA ---"
    assets_part = ""
    content_remaining = text
    
    if asset_marker in text:
        parts = text.rsplit(asset_marker, 1)
        if len(parts) == 2:
            content_remaining = parts[0]
            assets_part = asset_marker + parts[1] # ä¿ç•™æ ‡è®°å¤´

    # --- 2. å‰¥ç¦» References (åœ¨å‰©ä½™ä¸­æ‰¾) ---
    # å…¼å®¹ [[HEADER: References]] æˆ– [[HEADER: REFERENCE]] ç­‰
    ref_pattern = re.compile(r'(\[\[HEADER:\s*References?.*?\]\])', re.IGNORECASE)
    split_parts = ref_pattern.split(content_remaining, maxsplit=1)
    
    body_with_meta = ""
    ref_part = ""
    
    if len(split_parts) >= 3:
        # split_parts[0]: æ­£æ–‡
        # split_parts[1]: æ ‡é¢˜ ([[HEADER: References]])
        # split_parts[2]: å‚è€ƒæ–‡çŒ®åˆ—è¡¨å†…å®¹
        body_with_meta = split_parts[0].strip()
        ref_part = split_parts[1] + split_parts[2]
    else:
        body_with_meta = content_remaining.strip()

    # --- 3. å‰¥ç¦» Meta Data (ä»å¤´éƒ¨æ‰¾) ---
    # åŒ¹é…è¿ç»­çš„ [[META_...]] å—
    meta_pattern = re.compile(r'(\[\[META_.*?:.*?\]\]\s*)+')
    meta_match = meta_pattern.match(body_with_meta)
    
    meta_part = ""
    body_part = body_with_meta
    
    if meta_match:
        meta_part = meta_match.group(0).strip()
        # ä»åŒ¹é…ç»“æŸçš„ä½ç½®å¼€å§‹æˆªå–æ­£æ–‡
        body_part = body_with_meta[meta_match.end():].strip()

    # è¿”å› 4 ä¸ªéƒ¨åˆ†
    return meta_part, body_part, assets_part, ref_part

# --- æ ¸å¿ƒ LLM è°ƒç”¨å‡½æ•° (åº”ç”¨æ–°çš„åˆ‡åˆ†é€»è¾‘) ---
def run_smart_analysis(full_text_path_or_content: str, output_path: str, cache_path: str = None):
    # ã€æ¨¡å¼é…ç½®ã€‘
    API_KEY = "ollama" 
    BASE_URL = "http://localhost:11434/v1"
    MODEL_NAME = "qwen2.5:7b" 

    # 1. è¯»å–
    if os.path.isfile(full_text_path_or_content):
         with open(full_text_path_or_content, 'r', encoding='utf-8') as f: content = f.read()
    else:
        content = full_text_path_or_content

    # 2. é¢„å¤„ç†ï¼šåˆ†ç¦» RefMap
    ref_map_str = ""
    body_text = content
    map_match = re.search(r'\[\[REF_MAP_START\]\]\n(.*?)\n\[\[REF_MAP_END\]\]', content, re.DOTALL)
    if map_match:
        ref_map_str = map_match.group(1)
        body_text = content.replace(map_match.group(0), "").strip()
    
    # 3. å››æ®µå¼åˆ‡åˆ†
    meta_text, body_text, assets_text, raw_refs_text = split_content_smart(body_text)
    
    # 4. æ„å»ºä»»åŠ¡åˆ—è¡¨ (å¸¦ç±»å‹æ ‡è®°)
    # æ¯ä¸ª chunk ç»“æ„: {"text": str, "type": "meta"|"body"|"asset"}
    raw_chunks = []
    
    if meta_text:
        raw_chunks.append({"text": meta_text, "type": "meta"})
        
    if body_text:
        body_parts = split_text_into_chunks(body_text, MAX_CHUNK_CHARS)
        for part in body_parts:
            raw_chunks.append({"text": part, "type": "body"})
            
    if assets_text:
        raw_chunks.append({"text": assets_text, "type": "asset"})

    # ---------------------------------------------------------
    # é˜¶æ®µä¸€ï¼šä»»åŠ¡ç¼–æ’
    # ---------------------------------------------------------
    print(f"ğŸ“‹ [é˜¶æ®µä¸€] ç¼–æ’ä»»åŠ¡: æ€»ç‰‡æ®µ {len(raw_chunks)} ä¸ª | ç­–ç•¥: åˆ†ç±»å‹ä¸“ç”¨æç¤ºè¯")
    
    old_tasks_map = {}
    if cache_path and os.path.exists(cache_path):
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                old_json = json.load(f)
                for t in old_json.get("tasks", []):
                    old_tasks_map[t["chunk_hash"]] = t
        except: pass

    current_tasks = []
    pending_count = 0
    
    for i, item in enumerate(raw_chunks):
        c_text = item["text"]
        c_type = item["type"]
        h = compute_hash(c_text)
        
        cached_task = old_tasks_map.get(h)
        if cached_task and cached_task.get("status") == "success":
            task_entry = cached_task
            task_entry["id"] = i
            # å…¼å®¹æ—§ç¼“å­˜ï¼šå¦‚æœæ²¡æœ‰ type å­—æ®µï¼Œè¡¥ä¸Š
            if "type" not in task_entry: task_entry["type"] = c_type 
            print(f"   ğŸ”¹ Part {i+1} [{c_type.upper()}]: å‘½ä¸­ç¼“å­˜")
        else:
            task_entry = {
                "id": i,
                "type": c_type,  # å…³é”®ï¼šè®°å½•ä»»åŠ¡ç±»å‹
                "chunk_hash": h,
                "status": "pending",
                "src": c_text, 
                "trans": ""
            }
            pending_count += 1
            
        current_tasks.append(task_entry)

    # ä¿å­˜ JSON (æ³¨æ„ï¼šä¸å†ä¿å­˜å…¨å±€ system_promptï¼Œå› ä¸ºç°åœ¨æ˜¯åŠ¨æ€çš„)
    cache_structure = {
        "model": MODEL_NAME,
        "updated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        "tasks": current_tasks,
        "raw_references": raw_refs_text
    }
    
    if cache_path:
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(cache_structure, f, ensure_ascii=False, indent=2)
            
    if pending_count == 0:
        print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆã€‚")
        final_body = "\n".join([t["trans"] for t in current_tasks])
        
        final_refs = ""
        if raw_refs_text:
            final_refs = f"\n<header_block><src>References</src><trans>å‚è€ƒæ–‡çŒ® (åŸæ–‡ä¿ç•™)</trans></header_block>\n"
            clean_ref_content = re.sub(r'\[\[HEADER:.*?\]\]', '', raw_refs_text).strip()
            final_refs += f"<ref_block><src>{clean_ref_content}</src></ref_block>"

        with open(output_path, 'w', encoding='utf-8') as f: 
            f.write(final_body + "\n" + final_refs)
        return output_path

    # ---------------------------------------------------------
    # é˜¶æ®µäºŒï¼šæ‰§è¡Œæ¨ç† (åŠ¨æ€ Prompt)
    # ---------------------------------------------------------
    print(f"\nğŸš€ [é˜¶æ®µäºŒ] å¼€å§‹æ¨ç† (å‰©ä½™ {pending_count} ä¸ª)...")
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    # é¢„å¡«å…… Prompt Map
    PROMPT_MAP = {
        "meta": SYSTEM_PROMPT_META,
        "body": SYSTEM_PROMPT_BODY.replace("{ref_map_str}", ref_map_str),
        "asset": SYSTEM_PROMPT_ASSET.replace("{ref_map_str}", ref_map_str)
    }
    
    for task in current_tasks:
        if task["status"] == "success": continue
            
        idx = task["id"]
        t_type = task["type"]
        
        # æ‰“å°é¢„è§ˆ
        preview = task["src"][:30].replace('\n', ' ')
        print(f"   âš¡ Part {idx+1}/{len(current_tasks)} [{t_type.upper()}] ...", end="", flush=True)
        
        # --- å…³é”®ï¼šæ ¹æ®ç±»å‹é€‰æ‹© Prompt ---
        current_sys_prompt = PROMPT_MAP.get(t_type, PROMPT_MAP["body"])
        
        messages = [
            {"role": "system", "content": current_sys_prompt},
            {"role": "user", "content": task["src"]} # ä¸éœ€è¦å†åŠ  Chunk X/Y çš„åºŸè¯ï¼Œç›´æ¥å‘å†…å®¹
        ]
        
        success = False
        for attempt in range(3):
            try:
                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=messages,
                    temperature=0.1,
                    stream=False
                )
                res_text = response.choices[0].message.content
                
                # æ¸…æ´—
                res_text = re.sub(r'^```xml\s*', '', res_text)
                res_text = re.sub(r'```$', '', res_text)
                
                if res_text:
                    task["trans"] = res_text.strip()
                    task["status"] = "success"
                    print(" âœ…")
                    success = True
                    break
            except Exception as e:
                print(f" âš ï¸ {e}")
                time.sleep(2)
        
        if not success:
            task["status"] = "failed"
            print(" âŒ")
        
        if cache_path:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(cache_structure, f, ensure_ascii=False, indent=2)

    # ---------------------------------------------------------
    # é˜¶æ®µä¸‰ï¼šæœ€ç»ˆåˆå¹¶
    # ---------------------------------------------------------
    final_body = "\n".join([t["trans"] for t in current_tasks if t["status"] == "success"])
    
    final_refs = ""
    if raw_refs_text:
        final_refs = f"\n<header_block><src>References</src><trans>å‚è€ƒæ–‡çŒ®</trans></header_block>\n"
        clean_ref_content = re.sub(r'\[\[HEADER:.*?\]\]', '', raw_refs_text).strip()
        final_refs += f"<ref_block><src>{clean_ref_content}</src></ref_block>"

    with open(output_path, 'w', encoding='utf-8') as f: 
        f.write(final_body + "\n" + final_refs)
        
    return output_path

# --- è¾…åŠ©å‡½æ•°ï¼šä»»åŠ¡åˆ‡åˆ† (å‡çº§ç‰ˆï¼šå¼ºåˆ¶éš”ç¦»æ ‡é¢˜) ---
def split_text_into_chunks(text, max_chars):
    """
    å°†æ–‡æœ¬åˆ‡åˆ†ä¸º LLM ä»»åŠ¡ç‰‡æ®µã€‚
    ç­–ç•¥ï¼š
    1. é‡åˆ° [[HEADER:...]] å¿…é¡»å¼ºåˆ¶åˆ‡æ–­ï¼Œç‹¬ç«‹æˆä¸€ä¸ªä»»åŠ¡ã€‚
    2. æ™®é€šæ­£æ–‡å†æŒ‰ max_chars è¿›è¡Œé•¿åº¦åˆ‡åˆ†ã€‚
    """
    # 1. ä½¿ç”¨æ­£åˆ™ä¿ç•™åˆ†éš”ç¬¦çš„æ–¹å¼åˆ‡åˆ†
    # æ•è·ç»„ () ä¼šè®© split ä¿ç•™åˆ†éš”ç¬¦æœ¬èº«
    header_pattern = re.compile(r'(\[\[HEADER:.*?\]\])', re.IGNORECASE)
    segments = header_pattern.split(text)
    
    final_chunks = []
    
    for seg in segments:
        seg = seg.strip()
        if not seg: continue
        
        # --- æƒ…å†µ A: æ˜¯æ ‡é¢˜ -> å¼ºåˆ¶ç‹¬ç«‹ ---
        if header_pattern.match(seg):
            final_chunks.append(seg)
            
        # --- æƒ…å†µ B: æ˜¯æ­£æ–‡ -> æŒ‰é•¿åº¦åˆ‡åˆ† ---
        else:
            # åŸæœ‰çš„æŒ‰æ®µè½é•¿åº¦åˆå¹¶é€»è¾‘
            paragraphs = seg.split('\n\n')
            buffer = []
            buffer_len = 0
            
            for p in paragraphs:
                p = p.strip()
                if not p: continue
                
                # å¦‚æœå½“å‰ç¼“å†² + æ–°æ®µè½ > æœ€å¤§é•¿åº¦ï¼Œåˆ™å°åŒ…
                if buffer_len + len(p) > max_chars and buffer:
                    final_chunks.append("\n\n".join(buffer))
                    buffer = []
                    buffer_len = 0
                
                buffer.append(p)
                buffer_len += len(p)
            
            # å¤„ç†æ®‹ç•™ buffer
            if buffer:
                final_chunks.append("\n\n".join(buffer))
                
    return final_chunks

# --- HTML ç”Ÿæˆå™¨ (å®Œæ•´ç‰ˆï¼šå« CSS ç¾åŒ–ä¸å¼•ç”¨æ­£åˆ™åŒ¹é…) ---
def generate_html_report(llm_result_path: str, paper_vis_dir: str):
    # 1. ç¡®å®šè·¯å¾„
    # ä¼˜å…ˆè¯»å– JSON ç¼“å­˜ï¼Œå› ä¸ºåŒ…å«ç»“æ„åŒ–çš„ src å’Œ trans
    cache_path = llm_result_path.replace("_llm_result.txt", "_llm_cache.json")
    
    if not os.path.exists(cache_path):
        # å¦‚æœ JSON ä¸å­˜åœ¨ï¼Œå°è¯•å›é€€åˆ°è¯»å– txt (å…¼å®¹æ—§é€»è¾‘ï¼Œä½†æ¨èç”¨ json)
        print(f"âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°ç¼“å­˜æ–‡ä»¶ {cache_path}ï¼Œå°è¯•ä»…ä½¿ç”¨æ–‡æœ¬ç»“æœï¼ˆå¯èƒ½ä¸¢å¤±å¯¹é½ï¼‰ã€‚")
        return "Error: Cache JSON not found."

    raw_name = os.path.basename(paper_vis_dir)
    html_path = os.path.join(paper_vis_dir, f"{raw_name}_Report.html")
    assets_rel_path = "./assets"

    try:
        with open(cache_path, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
    except Exception as e:
        return f"è¯»å–ç¼“å­˜å¤±è´¥: {e}"

    tasks = cache_data.get("tasks", [])
    raw_refs = cache_data.get("raw_references", "")

    # --- é€šç”¨æ­£åˆ™ï¼šåŒ¹é…å‚è€ƒæ–‡çŒ®ç´¢å¼• [1], [1,2], [1-5], [10, 12-14] ---
    # è¯´æ˜ï¼š
    # \[        : å·¦ä¸­æ‹¬å·
    # \s* : å…è®¸ç©ºæ ¼
    # \d+       : æ•°å­—
    # (?: ...)* : éæ•è·ç»„ï¼ŒåŒ¹é…åç»­çš„ ", 2" æˆ– "-5" æˆ– "~8"
    # [\s,\-~]+ : åˆ†éš”ç¬¦
    # \]        : å³ä¸­æ‹¬å·
    citation_pattern = r'(\[\s*\d+(?:[\s,\-~]+\d+)*\s*\])'

    # --- å†…éƒ¨æ¸²æŸ“å‡½æ•°ï¼šå¤„ç†å·¦ä¾§åŸæ–‡ ---
    def render_src(text):
        if not text: return ""
        
        # 1. åŸºç¡€ HTML è½¬ä¹‰
        html = text \
            .replace("<", "&lt;").replace(">", "&gt;") \
            .replace("\n", "<br>")
        
        # 2. é«˜äº® Header å’Œ Meta
        html = re.sub(r'\[\[HEADER:\s*(.*?)\]\]', r'<div class="tag-header">\1</div>', html)
        html = re.sub(r'\[\[META_(.*?):\s*(.*?)\]\]', r'<div class="tag-meta">[\1] \2</div>', html)
        
        # 3. å¤„ç†èµ„æºå ä½ç¬¦ä¸è¯´æ˜
        html = re.sub(r'\[\[ASSET_PLACEHOLDER:\s*(.*?)\]\]', 
                      fr'<div class="tag-asset">[èµ„æºå ä½: \1]</div><img src="{assets_rel_path}/\1.png" class="mini-img">', html)
        
        def asset_cap_sub(m):
            aid, txt = m.group(1), m.group(2)
            return f'<div class="tag-asset-cap">[èµ„æºè¯´æ˜: {aid}]</div><div class="src-cap">{txt}</div><img src="{assets_rel_path}/{aid}.png" class="full-img">'
        html = re.sub(r'\[\[ASSET_CAPTION:\s*(.*?)\s*\|\s*(.*?)\]\]', asset_cap_sub, html)
        
        # 4. ã€æ–°å¢ã€‘é«˜äº®å‚è€ƒæ–‡çŒ®å¼•ç”¨
        html = re.sub(citation_pattern, r'<span class="citation-mark">\1</span>', html)
        
        return html

    # --- å†…éƒ¨æ¸²æŸ“å‡½æ•°ï¼šå¤„ç†å³ä¾§è¯‘æ–‡ ---
    def render_trans(text):
        if not text: return "..."
        if "FAILED" in text: return '<span style="color:red;">ç¿»è¯‘å¤±è´¥</span>'
        
        # 1. ç§»é™¤ LLM å¯èƒ½æ®‹ç•™çš„ markdown
        text = re.sub(r'^```xml', '', text).replace('```', '')
        
        # 2. è§£æä¼ª XML æ ‡ç­¾ -> HTML
        text = re.sub(r'<header>(.*?)</header>', r'<h3 class="trans-header">\1</h3>', text, flags=re.DOTALL)
        text = re.sub(r'<meta_title>(.*?)</meta_title>', r'<h1 class="trans-title">\1</h1>', text, flags=re.DOTALL)
        text = re.sub(r'<meta_author>(.*?)</meta_author>', r'<div class="trans-author">\1</div>', text, flags=re.DOTALL)
        text = re.sub(r'<p>(.*?)</p>', r'<p class="trans-p">\1</p>', text, flags=re.DOTALL)
        text = re.sub(r'<asset id=["\'](.*?)["\']>(.*?)</asset>', r'<div class="trans-asset-box"><b>å›¾è¡¨ \1:</b> \2</div>', text, flags=re.DOTALL)
        
        # 3. å¤„ç†è·³è½¬é“¾æ¥ Link
        text = re.sub(r'\[\[LINK:\s*([^\|]+)\|(.*?)\]\]', r'<a href="#\1" class="ref-link">\2</a>', text)
        
        # 4. ã€æ–°å¢ã€‘é«˜äº®å‚è€ƒæ–‡çŒ®å¼•ç”¨
        text = re.sub(citation_pattern, r'<span class="citation-mark">\1</span>', text)
        
        return text

    # --- æ„å»ºä¸» HTML å†…å®¹ ---
    rows_html = ""
    for task in tasks:
        src_html = render_src(task.get('src', ''))
        trans_html = render_trans(task.get('trans', ''))
        
        row_class = "normal-row"
        if "[[HEADER:" in task.get('src', ''): row_class = "header-row-bg"
        
        rows_html += f"""
        <div class="chunk-row {row_class}">
            <div class="col-src">{src_html}</div>
            <div class="col-trans">{trans_html}</div>
        </div>
        """

    # --- å¤„ç†å‚è€ƒæ–‡çŒ®éƒ¨åˆ† ---
    refs_html = ""
    if raw_refs:
        # ç®€å•çš„æ ¼å¼åŒ–ï¼šæ¢è¡Œè½¬ <br>ï¼Œå¹¶ä¹Ÿåº”ç”¨å¼•ç”¨é«˜äº®
        clean_refs = raw_refs.replace('\n', '<br>')
        clean_refs = re.sub(r'^(\[\d+\])', r'<b class="ref-id">\1</b>', clean_refs, flags=re.MULTILINE)
        
        refs_html = f"""
        <div class="chunk-row ref-row">
            <div class="col-src">
                <h3 style="color:#2c3e50; border-bottom:2px solid #eee; padding-bottom:10px;">References (Original)</h3>
                <div class="ref-content">{clean_refs}</div>
            </div>
            <div class="col-trans">
                <h3 style="color:#2c3e50; border-bottom:2px solid #eee; padding-bottom:10px;">å‚è€ƒæ–‡çŒ®</h3>
                <div style="color:#7f8c8d; padding:20px; text-align:center; background:#f9f9f9;">
                    (å‚è€ƒæ–‡çŒ®é€šå¸¸ä¿ç•™åŸæ–‡ä»¥ä¾›ç²¾ç¡®æ£€ç´¢ï¼Œæœªè¿›è¡Œç¿»è¯‘)
                </div>
            </div>
        </div>
        """

    # --- å®Œæ•´çš„ HTML æ¨¡æ¿ (å« CSS) ---
    html_template = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>{raw_name} - åŒè¯­å¯¹ç…§æŠ¥å‘Š</title>
    <style>
        :root {{ --bg: #f4f7f6; --border: #e0e0e0; --primary: #2c3e50; --link-color: #3498db; }}
        body {{ font-family: "Segoe UI", "Microsoft YaHei", sans-serif; margin: 0; background: var(--bg); color: #333; }}
        .container {{ max-width: 96%; margin: 30px auto; background: #fff; box-shadow: 0 4px 20px rgba(0,0,0,0.08); border-radius: 8px; overflow: hidden; }}
        
        /* å¸ƒå±€ç½‘æ ¼ */
        .chunk-row {{ display: flex; border-bottom: 1px solid var(--border); }}
        .chunk-row:last-child {{ border-bottom: none; }}
        .chunk-row:hover {{ background-color: #fafafa; transition: background 0.2s; }}
        
        .col-src {{ flex: 1; padding: 25px; border-right: 1px solid var(--border); font-family: "Cambria", serif; color: #444; font-size: 15px; line-height: 1.6; overflow-x: auto; background: #fff; }}
        .col-trans {{ flex: 1; padding: 25px; font-family: "Segoe UI", "Microsoft YaHei", sans-serif; color: #111; font-size: 16px; line-height: 1.7; background: #fcfcfc; }}
        
        /* æ ‡é¢˜ä¸å…ƒæ•°æ®æ ·å¼ */
        .header-row-bg {{ background-color: #f0f8ff; }}
        .tag-header {{ font-weight: 800; color: #2980b9; font-size: 1.1em; margin-bottom: 8px; display: inline-block; background: rgba(41,128,185,0.1); padding: 2px 8px; border-radius: 4px; }}
        .tag-meta {{ color: #16a085; font-size: 0.85em; margin-bottom: 4px; font-family: monospace; }}
        
        .trans-header {{ color: #2980b9; margin-top: 0; font-size: 1.4em; border-bottom: 1px solid #eee; padding-bottom: 10px; }}
        .trans-title {{ color: #2c3e50; text-align: center; font-size: 2em; margin: 20px 0; }}
        .trans-author {{ color: #16a085; text-align: center; margin-bottom: 30px; font-weight: bold; font-size: 1.1em; }}
        .trans-p {{ margin-bottom: 15px; text-align: justify; text-justify: inter-ideograph; }}
        
        /* èµ„æºå›¾ç‰‡æ ·å¼ */
        .tag-asset {{ background: #f0f0f0; padding: 2px 6px; font-size: 0.8em; color: #888; border-radius: 4px; }}
        .tag-asset-cap {{ background: #fff3cd; color: #856404; padding: 2px 6px; font-size: 0.8em; font-weight: bold; border-radius: 4px; margin-bottom: 5px; display:inline-block; }}
        .src-cap {{ font-style: italic; color: #666; margin-bottom: 10px; }}
        .mini-img {{ max-height: 40px; display: block; margin: 5px 0; opacity: 0.5; border: 1px solid #eee; }}
        .full-img {{ max-width: 98%; border: 1px solid #eee; margin: 10px auto; display: block; box-shadow: 0 2px 5px rgba(0,0,0,0.05); border-radius: 4px; }}
        
        .trans-asset-box {{ background: #fffdf5; padding: 15px; border-left: 4px solid #f1c40f; margin: 15px 0; border-radius: 0 4px 4px 0; font-size: 0.95em; color: #555; }}
        
        /* é“¾æ¥ä¸å¼•ç”¨æ ·å¼ (æ ¸å¿ƒä¿®æ”¹) */
        .ref-link {{ color: var(--link-color); text-decoration: none; background: rgba(52,152,219,0.1); padding: 0 4px; border-radius: 3px; font-weight: 500; }}
        .ref-link:hover {{ text-decoration: underline; background: rgba(52,152,219,0.2); }}
        
        .citation-mark {{ 
            color: #d35400; /* æ©™è¤è‰² */
            font-weight: bold;
            font-size: 0.9em;
            background-color: rgba(230, 126, 34, 0.12);
            padding: 0 3px;
            border-radius: 3px;
            cursor: help; /* é¼ æ ‡å˜æˆé—®å·ï¼Œæç¤ºå¯å…³æ³¨ */
            margin: 0 1px;
        }}
        .citation-mark:hover {{ 
            background-color: rgba(230, 126, 34, 0.3); 
            color: #c0392b;
        }}
        
        /* å‚è€ƒæ–‡çŒ®åˆ—è¡¨åŒº */
        .ref-id {{ color: #c0392b; font-weight: bold; margin-right: 5px; }}
        .ref-content {{ font-size: 0.9em; color: #555; line-height: 1.8; }}
        
    </style>
</head>
<body>
    <div class="container">
        {rows_html}
        {refs_html}
    </div>
</body>
</html>"""

    try:
        with open(html_path, 'w', encoding='utf-8') as f: f.write(html_template)
        return html_path
    except Exception as e:
        return f"å†™å…¥HTMLæ–‡ä»¶å¤±è´¥: {e}"