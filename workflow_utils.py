import os
import re
import time
import shutil
import platform
import fitz  # PyMuPDF
import json      # æ–°å¢
import hashlib   # æ–°å¢
import tkinter as tk
from tkinter import messagebox, font, ttk
from PIL import Image, ImageTk, ImageOps
from openai import OpenAI # ä½¿ç”¨ OpenAI å…¼å®¹åº“

# --- é…ç½®å¸¸é‡ ---
MAX_CHUNK_CHARS = 1000
TIMEOUT_MS = 600000
MAX_RETRIES = 3

# ==============================================================================
# 1. å®šä¹‰å¤šåœºæ™¯ä¸“ç”¨ Prompt
# ==============================================================================

# --- åœºæ™¯ A: å…ƒæ•°æ®ä¸“ç”¨ (å¼ºæ ¼å¼çº¦æŸ) ---
SYSTEM_PROMPT_META = """
ä½ æ˜¯ä¸€ä¸ªå…ƒæ•°æ®è§£æå™¨ã€‚è¯·å°†è¾“å…¥çš„è®ºæ–‡ã€æ ‡é¢˜ã€‘å’Œã€ä½œè€…ä¿¡æ¯ã€‘ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚

**æ ¸å¿ƒè§„åˆ™ (Strict Rules):**
1. **è¾“å…¥æ ¼å¼**: 
   - `[[META_TITLE: ...]]` -> è®ºæ–‡æ ‡é¢˜
   - `[[META_AUTHOR: ...]]` -> ä½œè€…/æœºæ„ä¿¡æ¯
2. **è¾“å‡ºæ ¼å¼ (å¿…é¡»ä¸¥æ ¼éµå®ˆ XML)**:
   - <meta_title>ä¸­æ–‡æ ‡é¢˜</meta_title>
   - <meta_author>ä½œè€…ä¸éœ€ç¿»è¯‘/æœºæ„ç¿»è¯‘</meta_author>
3. **ç¦æ­¢**: ç»å¯¹ä¸è¦è¾“å‡ºåŸæ–‡ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼Œä¸è¦è¾“å‡º markdown ä»£ç å—ã€‚
4. **äººåå¤„ç†**: ä½œè€…ä¸éœ€ç¿»è¯‘ï¼›æœºæ„åè¯·ç¿»è¯‘ã€‚
"""

# --- åœºæ™¯ B: æ­£æ–‡ä¸“ç”¨ (å­¦æœ¯é£æ ¼ + å¼•ç”¨å¤„ç†) ---
SYSTEM_PROMPT_BODY = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡ç¿»è¯‘å¼•æ“ã€‚è¯·å°†è¾“å…¥çš„å­¦æœ¯æ®µè½ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚
**è¾“å…¥èµ„æºæ˜ å°„è¡¨ (Ref Map):**
{ref_map_str}

**æ ¸å¿ƒè§„åˆ™:**
1. **é£æ ¼**: ä¿æŒå­¦æœ¯è®ºæ–‡çš„ä¸¥è°¨ã€å®¢è§‚ã€é€»è¾‘æ€§ã€‚
2. **ç»“æ„**: 
   - å½“åŸæ–‡è¡Œé¦–æ˜¾å¼åŒ…å« `[[HEADER: ...]]` æ ‡è®°ï¼Œä»£è¡¨ç‹¬ç«‹æ ‡é¢˜è¡Œæ—¶ï¼Œä½¿ç”¨ `<header>...</header>` æ ‡ç­¾ã€‚
   - **ç¦æ­¢**å°†æ­£æ–‡ä¸­çš„åˆ—è¡¨é¡¹ï¼ˆå¦‚ "1)", "3)" ç­‰ï¼‰éšæ„å‡çº§ä¸º `<header>`ã€‚
   - æ­£æ–‡æ®µè½ -> <p>è¯‘æ–‡</p> (ä¹Ÿå¯ä»¥ä¸åŠ  p æ ‡ç­¾ï¼Œç›´æ¥è¾“å‡ºæ–‡æœ¬)ã€‚
3. **å¼•ç”¨é“¾æ¥ (Link)**: 
   - ä»…é’ˆå¯¹å›¾è¡¨å¼•ç”¨ (å¦‚ "Fig. 1", "Table 2", "Eq. 3", "Algorithm. 4") ä½¿ç”¨ `[[LINK: ID|åŸæ–‡]]` æ ¼å¼ã€‚
   - **ä¸¥æ ¼ç¦æ­¢**å¯¹å‚è€ƒæ–‡çŒ®å¼•ç”¨ (å¦‚ "[1]", "[22]", "[1-5]") æ·»åŠ é“¾æ¥ã€‚å‚è€ƒæ–‡çŒ®å¼•ç”¨å¿…é¡»åŸæ ·ä¿ç•™ï¼Œå¦‚ `[22]`ã€‚
4. **ç¦æ­¢**: ç»å¯¹ä¸è¦è¾“å‡º <src> åŸæ–‡æ ‡ç­¾ã€‚åªè¾“å‡ºè¯‘æ–‡ã€‚
5. **ä¿ç•™**: é©¼å³°æ ¼å¼ä¸“æœ‰åè¯ã€ç¼©å†™ä¿ç•™åŸæ–‡ã€‚
"""

# --- åœºæ™¯ C: èµ„æºè¯´æ˜ä¸“ç”¨ (å›¾è¡¨/ç®—æ³•æè¿°) ---
SYSTEM_PROMPT_ASSET = """
ä½ æ˜¯ä¸€ä¸ªå›¾è¡¨è¯´æ˜ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·ç¿»è¯‘ä»¥ä¸‹å›¾è¡¨ã€ç®—æ³•æˆ–å…¬å¼çš„æ ‡é¢˜ä¸è¯´æ˜ã€‚

**è¾“å…¥èµ„æºæ˜ å°„è¡¨ (Ref Map):**
{ref_map_str}

**æ ¸å¿ƒè§„åˆ™:**
1. **è¾“å…¥æ ¼å¼**: `[[ASSET_CAPTION: ID | Text...]]`
2. **è¾“å‡ºæ ¼å¼**: <asset id="ID">ä¸­æ–‡è¯‘æ–‡</asset>
3. **å¤„ç†**: 
   - ä¿æŒç®€æ´ï¼Œå‡†ç¡®æè¿°å›¾è¡¨å«ä¹‰ã€‚
   - é‡åˆ°å ä½ç¬¦ `[[ASSET_PLACEHOLDER:...]]`ï¼Œè¯·ç›´æ¥å¿½ç•¥æˆ–è¾“å‡ºç©ºæ ‡ç­¾ã€‚
"""

def sanitize_filename(filename: str) -> str:
    if not filename: return "untitled"
    name = os.path.splitext(os.path.basename(filename))[0]
    return re.sub(r'[\\/*?:"<>|]', '', name).replace('\n','').strip()

def is_box_in_rect(box, rect, threshold=0.5):
    bx0, by0, bx1, by1 = box
    rx0, ry0, rx1, ry1 = rect
    ix0 = max(bx0, rx0); iy0 = max(by0, ry0)
    ix1 = min(bx1, rx1); iy1 = min(by1, ry1)
    if ix1 > ix0 and iy1 > iy0:
        inter = (ix1 - ix0) * (iy1 - iy0)
        b_area = (bx1 - bx0) * (by1 - by0)
        if b_area > 0 and inter / b_area > threshold: return True
    return False

def get_optimal_font(root):
    system = platform.system()
    available = set(font.families(root))
    if system == "Windows": candidates = ["Microsoft YaHei UI", "SimHei"]
    elif system == "Darwin": candidates = ["PingFang SC", "Heiti SC"]
    else: candidates = ["Noto Sans CJK SC", "WenQuanYi Micro Hei"]
    for f in candidates:
        if f in available: return f
    return "Helvetica"

# --- äº¤äº’å¼ç¼–è¾‘å™¨ ---
class LayoutEditor:
    def __init__(self, doc, initial_data):
        self.doc = doc
        self.data = initial_data 
        self.page_count = len(doc)
        self.current_page = 0
        
        self.root = tk.Tk()
        self.ui_font = get_optimal_font(self.root)
        self.root.title(f"PDF ç»“æ„åŒ–æ ¡å¯¹ (æ–°å¢: 5-æ ‡é¢˜ 6-ä½œè€… 7-é®ç½©)")
        
        if platform.system() == "Windows":
            self.root.state('zoomed')
        else:
            w = self.root.winfo_screenwidth()
            h = self.root.winfo_screenheight()
            self.root.geometry(f"{w}x{h}+0+0")

        self.current_tool_type = tk.StringVar(value="Figure") 
        self.current_id = tk.IntVar(value=1)
        self.current_role = tk.StringVar(value="Body") 
        
        # é¢œè‰²å®šä¹‰
        self.colors = {
            "Figure": "#e74c3c",    # çº¢
            "Table": "#3498db",     # è“
            "Equation": "#27ae60",  # ç»¿
            "Algorithm": "#9b59b6", # ç´«
            "Title": "#d35400",     # æ·±æ©™ (æ ‡é¢˜)
            "Author": "#1abc9c",    # é’è‰² (ä½œè€…)
            "Mask": "#7f8c8d",      # ç°è‰² (é®ç½©)
            "ContentArea": "#f1c40f" # é»„
        }

        self.main_paned = tk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        self.main_paned.pack(fill=tk.BOTH, expand=True)

        self.canvas_frame = tk.Frame(self.main_paned, bg="#555")
        self.sidebar_frame = tk.Frame(self.main_paned, bg="#f0f0f0", width=340)
        
        self.main_paned.add(self.canvas_frame, stretch="always")
        self.main_paned.add(self.sidebar_frame, stretch="never")

        self.setup_sidebar()

        self.v_scroll = tk.Scrollbar(self.canvas_frame, orient=tk.VERTICAL)
        self.h_scroll = tk.Scrollbar(self.canvas_frame, orient=tk.HORIZONTAL)
        self.canvas = tk.Canvas(self.canvas_frame, bg="#555",
                                yscrollcommand=self.v_scroll.set, xscrollcommand=self.h_scroll.set)
        self.v_scroll.config(command=self.canvas.yview)
        self.h_scroll.config(command=self.canvas.xview)
        
        self.v_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        self.h_scroll.pack(side=tk.BOTTOM, fill=tk.X)
        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        self.canvas.bind("<ButtonPress-1>", self.on_mouse_down)
        self.canvas.bind("<B1-Motion>", self.on_mouse_drag)
        self.canvas.bind("<ButtonRelease-1>", self.on_mouse_up)
        self.canvas.bind("<Button-3>", self.on_right_click)
        self.root.bind("<Key>", self.on_key_press)

        self.scale = 1.5 
        self.rect_id_map = {}
        self.start_x = None; self.start_y = None; self.current_rect_id = None
        
        self.update_id_suggestion()
        self.load_page()
        self.root.mainloop()

    def setup_sidebar(self):
        f_title = (self.ui_font, 14, "bold")
        f_norm = (self.ui_font, 12)
        f_bold = (self.ui_font, 12, "bold")
        
        p = 10
        tk.Label(self.sidebar_frame, text="å·¥å…·ç®± (Toolbox)", font=f_title, bg="#f0f0f0").pack(pady=(15, 10))
        
        # 1. Type
        type_frame = tk.LabelFrame(self.sidebar_frame, text="1. å…ƒç´ ç±»å‹", font=f_bold, bg="#f0f0f0")
        type_frame.pack(fill=tk.X, padx=p, pady=5)
        
        # åˆ†ç»„æ˜¾ç¤º
        types_group1 = [
            ("å›¾ (Figure) - [1]", "Figure"), 
            ("è¡¨ (Table) - [2]", "Table"), 
            ("å¼ (Equation) - [3]", "Equation"), 
            ("ç®— (Algorithm) - [4]", "Algorithm")
        ]
        types_group2 = [
            ("æ ‡é¢˜ (Title) - [5]", "Title"),
            ("ä½œè€… (Author) - [6]", "Author"),
            ("é®ç½© (Mask) - [7]", "Mask")
        ]
        
        for text, val in types_group1:
            tk.Radiobutton(type_frame, text=text, variable=self.current_tool_type, value=val, 
                           command=self.update_id_suggestion, font=f_norm, bg="#f0f0f0", anchor="w").pack(fill=tk.X, padx=5)
        
        ttk.Separator(type_frame, orient='horizontal').pack(fill='x', padx=5, pady=5)
        
        for text, val in types_group2:
            tk.Radiobutton(type_frame, text=text, variable=self.current_tool_type, value=val, 
                           command=self.update_id_suggestion, font=f_norm, bg="#f0f0f0", anchor="w").pack(fill=tk.X, padx=5)
        
        ttk.Separator(type_frame, orient='horizontal').pack(fill='x', padx=5, pady=5)
        tk.Radiobutton(type_frame, text="æ­£æ–‡èŒƒå›´ - [0]", variable=self.current_tool_type, value="ContentArea", 
                        command=self.update_id_suggestion, font=f_norm, bg="#f0f0f0", anchor="w").pack(fill=tk.X, padx=5)

        # 2. Props
        prop_frame = tk.LabelFrame(self.sidebar_frame, text="2. å±æ€§è®¾å®š", font=f_bold, bg="#f0f0f0")
        prop_frame.pack(fill=tk.X, padx=p, pady=5)
        
        row1 = tk.Frame(prop_frame, bg="#f0f0f0")
        row1.pack(fill=tk.X, padx=5, pady=5)
        tk.Label(row1, text="ç¼–å· (ID):", font=f_norm, bg="#f0f0f0").pack(side=tk.LEFT)
        tk.Button(row1, text="-", command=lambda: self.adj_id(-1), font=f_bold, width=3).pack(side=tk.LEFT, padx=5)
        self.id_entry = tk.Entry(row1, textvariable=self.current_id, width=5, font=f_norm, justify='center')
        self.id_entry.pack(side=tk.LEFT)
        tk.Button(row1, text="+", command=lambda: self.adj_id(1), font=f_bold, width=3).pack(side=tk.LEFT, padx=5)
        
        tk.Label(prop_frame, text="è§’è‰² (Role):", font=f_norm, bg="#f0f0f0").pack(anchor="w", padx=5, pady=(5,0))
        tk.Radiobutton(prop_frame, text="å†…å®¹æˆªå›¾ (Body)", variable=self.current_role, value="Body", font=f_norm, bg="#f0f0f0").pack(anchor="w", padx=15)
        tk.Radiobutton(prop_frame, text="æ ‡é¢˜æ–‡æœ¬ (Caption)", variable=self.current_role, value="Caption", font=f_norm, bg="#f0f0f0").pack(anchor="w", padx=15)

        # 3. List
        list_frame = tk.LabelFrame(self.sidebar_frame, text="å½“å‰é¡µåˆ—è¡¨ (Delåˆ é™¤)", font=f_bold, bg="#f0f0f0")
        list_frame.pack(fill=tk.BOTH, expand=True, padx=p, pady=5)
        self.item_listbox = tk.Listbox(list_frame, bg="white", height=10, font=(self.ui_font, 11))
        self.item_listbox.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.item_listbox.bind("<Delete>", self.delete_selected_list_item)

        # 4. Nav
        nav_frame = tk.Frame(self.sidebar_frame, bg="#f0f0f0")
        nav_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=p, pady=20)
        tk.Button(nav_frame, text="< ä¸Šä¸€é¡µ", command=self.prev_page, font=f_norm).pack(side=tk.LEFT)
        self.btn_next = tk.Button(nav_frame, text="ä¸‹ä¸€é¡µ >", command=self.next_page, font=f_bold, bg="#2ecc71", fg="white")
        self.btn_next.pack(side=tk.RIGHT)

    def adj_id(self, delta):
        val = self.current_id.get() + delta
        if val < 1: val = 1
        self.current_id.set(val)

    def set_tool(self, tool_type):
        self.current_tool_type.set(tool_type)
        self.update_id_suggestion()

    def update_id_suggestion(self):
        ctype = self.current_tool_type.get()
        if ctype in ["ContentArea", "Mask", "Title", "Author"]: return
        
        max_id = 0
        for p_idx in self.data:
            for item in self.data[p_idx]:
                if item['type'] == ctype:
                    max_id = max(max_id, item.get('id', 0))
        self.current_id.set(max_id + 1)
        self.current_role.set("Body")

    def load_page(self):
        self.canvas.delete("all")
        self.rect_id_map = {}
        self.item_listbox.delete(0, tk.END)
        
        page = self.doc[self.current_page]
        pix = page.get_pixmap(matrix=fitz.Matrix(self.scale, self.scale))
        self.tk_img = ImageTk.PhotoImage(Image.frombytes("RGB", [pix.width, pix.height], pix.samples))
        
        self.canvas.config(scrollregion=(0, 0, pix.width, pix.height))
        self.canvas.create_image(0, 0, anchor=tk.NW, image=self.tk_img)
        
        self.btn_next.config(text="ç”Ÿæˆç»“æœ (Finish)" if self.current_page == self.page_count - 1 else "ä¸‹ä¸€é¡µ >")
        
        if self.current_page in self.data:
            for idx, item in enumerate(self.data[self.current_page]):
                self.draw_box(item, idx)
                desc = f"[{item['type']}]"
                if item['type'] not in ["ContentArea", "Mask", "Title", "Author"]:
                    desc += f" {item['id']} - {item['role']}"
                self.item_listbox.insert(tk.END, desc)

    def draw_box(self, item, idx):
        r = item['rect']
        x0, y0, x1, y1 = r.x0*self.scale, r.y0*self.scale, r.x1*self.scale, r.y1*self.scale
        color = self.colors.get(item['type'], "black")
        
        dash = (4, 4) if item.get('role') == 'Caption' else None
        width = 3 if item['type'] == 'ContentArea' else 2
        stipple = 'gray50' if item['type'] == 'Mask' else '' # é®ç½©åŠ é˜´å½±
        
        rect_id = self.canvas.create_rectangle(x0, y0, x1, y1, outline=color, width=width, dash=dash, stipple=stipple, tags="box")
        
        label_txt = item['type']
        if item['type'] not in ['ContentArea', 'Mask', 'Title', 'Author']:
            label_txt += f" {item['id']} ({item['role'][0]})"
        
        bg_id = self.canvas.create_rectangle(x0, y0-20, x0+len(label_txt)*9, y0, fill=color, outline=color, tags="box")
        txt_id = self.canvas.create_text(x0+2, y0-10, text=label_txt, anchor=tk.W, fill="white", font=("Arial", 10, "bold"), tags="box")
        
        self.rect_id_map[rect_id] = idx
        self.rect_id_map[bg_id] = idx
        self.rect_id_map[txt_id] = idx

    def on_mouse_down(self, event):
        self.start_x = self.canvas.canvasx(event.x)
        self.start_y = self.canvas.canvasy(event.y)
        color = self.colors.get(self.current_tool_type.get(), "black")
        self.current_rect_id = self.canvas.create_rectangle(self.start_x, self.start_y, self.start_x, self.start_y, outline=color, width=2, dash=(2,2))

    def on_mouse_drag(self, event):
        self.canvas.coords(self.current_rect_id, self.start_x, self.start_y, self.canvas.canvasx(event.x), self.canvas.canvasy(event.y))

    def on_mouse_up(self, event):
        x0, x1 = sorted([self.start_x, self.canvas.canvasx(event.x)])
        y0, y1 = sorted([self.start_y, self.canvas.canvasy(event.y)])
        self.canvas.delete(self.current_rect_id)
        
        if x1 - x0 < 10 or y1 - y0 < 10: return
        
        pdf_rect = fitz.Rect(x0/self.scale, y0/self.scale, x1/self.scale, y1/self.scale)
        
        new_item = {
            'rect': pdf_rect,
            'type': self.current_tool_type.get(),
            'id': self.current_id.get(),
            'role': self.current_role.get()
        }
        
        if self.current_page not in self.data: self.data[self.current_page] = []
        if new_item['type'] == 'ContentArea':
             self.data[self.current_page] = [x for x in self.data[self.current_page] if x['type'] != 'ContentArea']

        self.data[self.current_page].append(new_item)
        
        # è‡ªåŠ¨åˆ‡æ¢ role é€»è¾‘
        no_caption_types = ['ContentArea', 'Equation', 'Mask', 'Title', 'Author']
        if new_item['type'] not in no_caption_types and new_item['role'] == 'Body':
            self.current_role.set("Caption")
        
        self.load_page()

    def on_right_click(self, event):
        x, y = self.canvas.canvasx(event.x), self.canvas.canvasy(event.y)
        items = self.canvas.find_overlapping(x-2, y-2, x+2, y+2)
        for item_id in items:
            if item_id in self.rect_id_map:
                idx = self.rect_id_map[item_id]
                del self.data[self.current_page][idx]
                self.load_page()
                break

    def delete_selected_list_item(self, event):
        sel = self.item_listbox.curselection()
        if sel:
            idx = sel[0]
            del self.data[self.current_page][idx]
            self.load_page()

    def on_key_press(self, event):
        k = event.keysym
        if k == '1': self.set_tool("Figure")
        elif k == '2': self.set_tool("Table")
        elif k == '3': self.set_tool("Equation")
        elif k == '4': self.set_tool("Algorithm") 
        elif k == '5': self.set_tool("Title")   # æ–°å¢
        elif k == '6': self.set_tool("Author")  # æ–°å¢
        elif k == '7': self.set_tool("Mask")    # æ–°å¢
        elif k == '0': self.set_tool("ContentArea")
        elif k in ['space', 'Return', 'Right']: self.next_page()
        elif k in ['BackSpace', 'Left']: self.prev_page()

    def next_page(self):
        # 1. è·å–å½“å‰é¡µçš„æ­£æ–‡åŒºåŸŸ (ContentArea)
        curr_content = next((x for x in self.data.get(self.current_page, []) if x['type'] == 'ContentArea'), None)
        next_idx = self.current_page + 1
        
        if next_idx < self.page_count:
            # ç¡®ä¿ä¸‹ä¸€é¡µçš„æ•°æ®åˆ—è¡¨å·²åˆå§‹åŒ–
            if next_idx not in self.data: 
                self.data[next_idx] = []
            
            # --- ã€æ ¸å¿ƒä¿®å¤ã€‘æ™ºèƒ½ç»§æ‰¿é€»è¾‘ ---
            # æ£€æŸ¥ä¸‹ä¸€é¡µæ˜¯å¦å·²ç»æœ‰äº† ContentArea (ä¾‹å¦‚ä»å†å²è®°å½•åŠ è½½çš„)
            next_has_content = any(x['type'] == 'ContentArea' for x in self.data[next_idx])
            
            # åªæœ‰å½“ä¸‹ä¸€é¡µã€æ²¡æœ‰ã€‘æ­£æ–‡åŒºåŸŸæ—¶ï¼Œæ‰å°è¯•ç»§æ‰¿å½“å‰é¡µçš„
            if not next_has_content and curr_content:
                # é¢å¤–çš„æ™ºèƒ½æ£€æŸ¥ï¼šåªæœ‰å½“é¡µé¢å°ºå¯¸ä¸€è‡´æ—¶æ‰ç»§æ‰¿ï¼Œé˜²æ­¢æ¨ªé¡µ/ç«–é¡µåˆ‡æ¢å¯¼è‡´æ¡†è·‘é£
                if self.doc[self.current_page].rect == self.doc[next_idx].rect:
                     # å¤åˆ¶ä¸€ä»½å½“å‰é¡µçš„æ¡†è¿‡å»
                     self.data[next_idx].insert(0, curr_content.copy())
            
            # ç¿»é¡µ
            self.current_page += 1
            self.load_page()
        else:
            if messagebox.askyesno("å®Œæˆ", "ç¡®è®¤å®Œæˆæ‰€æœ‰æ ¡å¯¹ï¼Ÿ"):
                self.root.destroy()

    def prev_page(self):
        if self.current_page > 0:
            self.current_page -= 1
            self.load_page()

def split_long_buffer_safely(text, max_len):
    """
    å°†è¶…é•¿æ–‡æœ¬æ‹†åˆ†ä¸ºå¤šä¸ªç‰‡æ®µï¼Œç¡®ä¿æ‹†åˆ†ç‚¹åœ¨å¥å­ç»“æŸå¤„ã€‚
    ä¿®å¤ï¼šä½¿ç”¨è´Ÿå‘åç» (Negative Look-behind) ä¿æŠ¤å¸¸è§ç¼©å†™ (Fig., Eq., al. ç­‰) ä¸è¢«åˆ‡æ–­ã€‚
    """
    if len(text) <= max_len:
        return [text]
    
    # --- æ ¸å¿ƒä¿®æ”¹ï¼šä¿æŠ¤ç¼©å†™è¯çš„æ­£åˆ™ ---
    # å«ä¹‰ï¼š
    # 1. (?<!...) : è´Ÿå‘åç»ï¼Œå¦‚æœå¥å·å‰é¢æ˜¯è¿™äº›è¯ï¼Œåˆ™ä¸åŒ¹é…
    # 2. \b       : å•è¯è¾¹ç•Œï¼Œé˜²æ­¢åŒ¹é…åˆ°éå•è¯ç»“å°¾
    # 3. (?<=[.?!;]) : æ­£å‘åç»ï¼Œå¿…é¡»ä»¥æ ‡ç‚¹ç»“å°¾
    # 4. \s+      : ä¸­é—´æœ‰ç©ºæ ¼
    # 5. (?=[A-Z0-9]) : åé¢æ¥å¤§å†™å­—æ¯æˆ–æ•°å­—
    
    protect_pattern = (
        r'(?<!\bFig\.)(?<!\bFigs\.)'  # Fig. / Figs.
        r'(?<!\bEq\.)(?<!\bEqs\.)'    # Eq. / Eqs.
        r'(?<!\bTab\.)(?<!\bTabs\.)'  # Tab. / Tabs.
        r'(?<!\bRef\.)(?<!\bRefs\.)'  # Ref. / Refs.
        r'(?<!\bVol\.)(?<!\bno\.)'    # Vol. / no.
        r'(?<!\bal\.)(?<!\bvs\.)'     # et al. / vs.
        r'(?<!\bi\.e\.)(?<!\be\.g\.)' # i.e. / e.g.
    )
    
    # 2. åˆ‡åˆ†é€»è¾‘ï¼š
    # (?<=[.?!;]) : å¿…é¡»ä»¥æ ‡ç‚¹ç»“å°¾
    # \s+         : åˆ†éš”ç¬¦æ˜¯ç©ºæ ¼
    # (?=[A-Z0-9\[]) : åé¢æ¥å¤§å†™/æ•°å­—/æ–¹æ‹¬å·(å¼•ç”¨)
    split_marker = r'(?<=[.?!;])\s+(?=[A-Z0-9\[])'
    
    final_pattern = protect_pattern + split_marker

    try:
        # ä½¿ç”¨ IGNORECASE ä»¥é˜² fig. 1
        sentences = re.split(final_pattern, text, flags=re.IGNORECASE)
    except re.error:
        # å¦‚æœç¯å¢ƒä¸æ”¯æŒå¤æ‚ lookbehindï¼Œå›é€€åˆ°ç®€å•åˆ‡åˆ†
        print("âš ï¸ [Warning] Regex lookbehind failed, using simple split.")
        sentences = re.split(r'(?<=[.?!;])\s+(?=[A-Z0-9])', text)
    
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°å¥å­ä¼šè¶…é•¿ï¼Œä¸”å½“å‰å—ä¸ä¸ºç©º -> å°åŒ…
        if len(current_chunk) + len(sentence) > max_len and current_chunk:
            chunks.append(current_chunk)
            current_chunk = sentence
        else:
            # æ‹¼æ¥
            if current_chunk:
                current_chunk += " " + sentence
            else:
                current_chunk = sentence
                
    if current_chunk:
        chunks.append(current_chunk)
        
    return chunks

# --- è¾…åŠ©å‡½æ•°ï¼šæ®µè½æµå¤„ç† (å«é•¿éš¾å¥æ‹†åˆ†) ---
def smart_merge_paragraphs(blocks, max_split_len=500):
    """
    blocks: åŸå§‹æ–‡æœ¬å—æµ
    è°ƒè¯•å¢å¼ºç‰ˆï¼šä½¿ç”¨ repr() æ˜¾ç¤ºä¸å¯è§å­—ç¬¦ï¼Œå¼ºåˆ¶æ‰“å° Fig é™„è¿‘çš„åŒ¹é…æƒ…å†µ
    """
    if not blocks: return []
    merged = []
    buffer = ""
    
    terminals = ('.', '?', '!', ':', ';', 'ã€‚', 'ï¼Ÿ', 'ï¼', 'ï¼š', 'ï¼›')
    hard_boundary_pattern = re.compile(r'^\[\[(HEADER|ASSET_|META_).*?\]\]')
    
    # --- è°ƒè¯•ç”¨ï¼šæ”¾å®½æ­£åˆ™ï¼Œå…ˆæŠ“åˆ°å†è¯´ ---
    # ç§»é™¤ (?:^|\s) é™åˆ¶ï¼Œç›´æ¥åŒ¹é…ç»“å°¾çš„å…³é”®è¯
    hanging_abbrev_pattern = re.compile(
        r'(Fig|Figure|Eq|Equation|Tab|Table|Ref|Reference|Sec|Section)\.?\s*$', 
        re.IGNORECASE
    )

    print(f"ğŸ” [DEBUG] å¼€å§‹å¤„ç† {len(blocks)} ä¸ªæ–‡æœ¬å—...")

    for i, block in enumerate(blocks):
        block = block.strip()
        if not block: continue
        
        # 1. ç¡¬æ€§è¾¹ç•Œ -> å¼ºåˆ¶åˆ·æ–°
        if hard_boundary_pattern.match(block):
            if buffer:
                merged.extend(split_long_buffer_safely(buffer, max_split_len))
                buffer = ""
            merged.append(block)
            continue
        
        # 2. åˆå§‹åŒ–
        if not buffer:
            buffer = block
            continue
            
        # 3. åˆå¹¶é€»è¾‘
        prev_end_char = buffer[-1] if buffer else ""
        
        # --- ğŸ•µï¸â€â™‚ï¸ æ˜¾å¾®é•œè°ƒè¯•åŒº ---
        # å– buffer æœ€å 20 ä¸ªå­—ç¬¦
        tail = buffer[-20:]
        # å¦‚æœç»“å°¾çœ‹èµ·æ¥åƒæ˜¯ Figï¼Œæ‰“å°å‡ºæ¥çœ‹çœ‹ç©¶ç«Ÿæ˜¯ä»€ä¹ˆ
        if "Fig" in tail or "Tab" in tail:
            is_match = hanging_abbrev_pattern.search(buffer) is not None
            print(f"ğŸ§ [Chunk {i}] å‘ç°ç–‘ä¼¼ç¼©å†™:")
            print(f"   Bufferå°¾éƒ¨(repr): {repr(tail)}") # <--- é‡ç‚¹çœ‹è¿™é‡Œï¼
            print(f"   æ­£åˆ™åŒ¹é…ç»“æœ: {is_match}")
            if not is_match:
                print(f"   âš ï¸ è­¦å‘Šï¼šè™½ç„¶åŒ…å«å…³é”®å­—ï¼Œä½†æ­£åˆ™æœªåŒ¹é…ï¼")

        # æƒ…å†µ A: è¿å­—ç¬¦
        if prev_end_char == '-':
            buffer = buffer[:-1] + block
            
        # --- æƒ…å†µ B: æ‚¬æŒ‚ç¼©å†™ä¿®å¤ ---
        elif hanging_abbrev_pattern.search(buffer):
            # print(f"ğŸ”— [MERGE] æˆåŠŸåˆå¹¶è·¨è¡Œç¼©å†™: ...{buffer[-10:]} + {block[:10]}...")
            buffer = buffer + " " + block
            
        # æƒ…å†µ C: å¥å­æœªç»“æŸ
        elif (not buffer.endswith(terminals)) or (block[0].islower()):
            buffer = buffer + " " + block
            
        # æƒ…å†µ D: æ­£å¸¸åˆ†æ®µ
        else:
            # è°ƒè¯•ï¼šå¦‚æœåˆšæ‰ Fig æ²¡åŒ¹é…ä¸Šï¼Œè¿™é‡Œå°±ä¼šæ‰§è¡Œåˆ‡åˆ†
            if "Fig" in tail:
                print(f"âœ‚ï¸ [SPLIT] æ‰§è¡Œåˆ‡åˆ† (å› ä¸ºæ­£åˆ™æœªåŒ¹é…): ...{repr(tail)} || {repr(block[:10])}...")
            
            merged.extend(split_long_buffer_safely(buffer, max_split_len))
            buffer = block 

    if buffer:
        merged.extend(split_long_buffer_safely(buffer, max_split_len))
    
    return merged

# --- æ ¸å¿ƒæå–é€»è¾‘ ---
def extract_text_and_save_assets_smart(pdf_path: str, raw_text_dir: str, vis_output_root: str) -> tuple[str, str, str, int]:
    if not os.path.exists(pdf_path): raise FileNotFoundError(f"PDF missing: {pdf_path}")
    
    clean_name = sanitize_filename(pdf_path)
    os.makedirs(raw_text_dir, exist_ok=True)
    txt_path = os.path.join(raw_text_dir, f"{clean_name}_context.txt")
    
    # èµ„æºç›®å½• (extracted_output/{PaperName}/assets)
    extracted_assets_dir = os.path.join(raw_text_dir, clean_name, "assets")
    
    # æ ‡æ³¨é…ç½®æ–‡ä»¶è·¯å¾„
    layout_config_path = os.path.join(raw_text_dir, clean_name, "layout_config.json")
    
    if not os.path.exists(os.path.dirname(layout_config_path)):
        os.makedirs(os.path.dirname(layout_config_path), exist_ok=True)

    doc = fitz.open(pdf_path)
    
    # =========================================================
    # 1. åˆå§‹åŒ–æ•°æ® (æ ¸å¿ƒä¿®å¤ï¼šé€é¡µåˆå¹¶å†å²ä¸é»˜è®¤å€¼)
    # =========================================================
    init_data = {}
    saved_json = {}

    # å°è¯•è¯»å–å†å²æ–‡ä»¶
    if os.path.exists(layout_config_path):
        print(f"ğŸ“‚ æ£€æµ‹åˆ°å†å²æ ‡æ³¨è®°å½•: {layout_config_path}ï¼Œæ­£åœ¨åŠ è½½...")
        try:
            with open(layout_config_path, 'r', encoding='utf-8') as f:
                saved_json = json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å†å²è®°å½•å¤±è´¥ ({e})ï¼Œå°†å¿½ç•¥å†å²æ–‡ä»¶ã€‚")
            saved_json = {}

    # éå†æ¯ä¸€é¡µè¿›è¡Œåˆå§‹åŒ–
    for i, page in enumerate(doc):
        w, h = page.rect.width, page.rect.height
        page_items = []
        
        # A. å°è¯•è·å–è¯¥é¡µçš„å†å²æ•°æ®
        # JSON çš„ key æ˜¯å­—ç¬¦ä¸²ç±»å‹çš„æ•°å­— "0", "1"...
        if str(i) in saved_json:
            raw_items = saved_json[str(i)]
            for item in raw_items:
                # æ¢å¤ fitz.Rect å¯¹è±¡
                r = item['rect'] # [x0, y0, x1, y1]
                page_items.append({
                    'rect': fitz.Rect(r[0], r[1], r[2], r[3]),
                    'type': item['type'],
                    'id': item['id'],
                    'role': item['role']
                })
        
        # B. æ£€æŸ¥å¹¶è¡¥å…¨ ContentArea (æ­£æ–‡èŒƒå›´)
        # å¦‚æœå†å²è®°å½•é‡Œæ²¡æœ‰è¿™ä¸€é¡µï¼Œæˆ–è€…è¿™ä¸€é¡µè¢«åˆ é™¤äº†æ­£æ–‡èŒƒå›´ï¼Œå¿…é¡»è¡¥ä¸€ä¸ªé»˜è®¤çš„
        has_content_area = any(x['type'] == 'ContentArea' for x in page_items)
        
        if not has_content_area:
            # é»˜è®¤æ­£æ–‡èŒƒå›´ï¼šé¡µçœ‰ç•™ 8% ç©ºç™½
            default_rect = fitz.Rect(0, h*0.08, w, h*0.92)
            # æ’å…¥åˆ°åˆ—è¡¨å¤´éƒ¨ï¼Œç¡®ä¿å±‚çº§åœ¨æœ€åº•å±‚ï¼ˆè™½ç„¶é€»è¾‘ä¸Šä¸å½±å“ï¼Œä½†çœ‹ç€èˆ’æœï¼‰
            page_items.insert(0, {
                'rect': default_rect,
                'type': 'ContentArea',
                'id': 0,      # ID å¯¹ ContentArea æ— æ„ä¹‰ï¼Œç»™ 0
                'role': 'Body'
            })
            
        init_data[i] = page_items

    # =========================================================
    # 2. å¯åŠ¨äº¤äº’ç¼–è¾‘å™¨
    # =========================================================
    editor = LayoutEditor(doc, init_data)
    verified_data = editor.data

    # =========================================================
    # 3. ä¿å­˜æ ‡æ³¨ç»“æœ (åºåˆ—åŒ–)
    # =========================================================
    serializable_data = {}
    for page_idx, items in verified_data.items():
        serializable_data[page_idx] = []
        for item in items:
            r = item['rect']
            serializable_data[page_idx].append({
                'rect': [r.x0, r.y0, r.x1, r.y1],
                'type': item['type'],
                'id': item['id'],
                'role': item['role']
            })
            
    with open(layout_config_path, 'w', encoding='utf-8') as f:
        json.dump(serializable_data, f, indent=2)
    print(f"ğŸ’¾ æ ‡æ³¨è¿›åº¦å·²ä¿å­˜è‡³: {layout_config_path}")

    # =========================================================
    # 4. åç»­å¤„ç† (èµ„æºæå– & æ–‡æœ¬ç”Ÿæˆ)
    # =========================================================
    if os.path.exists(extracted_assets_dir): shutil.rmtree(extracted_assets_dir)
    os.makedirs(extracted_assets_dir, exist_ok=True)

    print(f"ğŸ§© æ­£åœ¨å¤„ç†èµ„æº (ä¿å­˜è‡³: {extracted_assets_dir})...")
    assets_agg = {}
    meta_info_blocks = [] 
    
    for p_idx in range(len(doc)):
        page = doc[p_idx]
        items = verified_data.get(p_idx, [])
        
        for item in items:
            if item['type'] == 'Title':
                txt = page.get_text("text", clip=item['rect']).strip().replace('\n', ' ')
                meta_info_blocks.append(f"[[META_TITLE: {txt}]]")
                continue
            if item['type'] == 'Author':
                txt = page.get_text("text", clip=item['rect']).strip().replace('\n', ' ')
                meta_info_blocks.append(f"[[META_AUTHOR: {txt}]]")
                continue
            
            if item['type'] in ['ContentArea', 'Mask']: continue
            
            key = f"{item['type']}_{item['id']}" 
            if key not in assets_agg: assets_agg[key] = {'bodies': [], 'captions': [], 'rects': [], 'page': p_idx}
            assets_agg[key]['rects'].append(item['rect']) 
            
            if item['role'] == 'Body':
                pix = page.get_pixmap(clip=item['rect'], matrix=fitz.Matrix(3,3))
                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                assets_agg[key]['bodies'].append(img)
            elif item['role'] == 'Caption':
                text = page.get_text("text", clip=item['rect']).strip().replace('\n', ' ')
                assets_agg[key]['captions'].append(text)

    ref_map = [] 
    asset_count = 0
    final_asset_captions = {} 

    for key, data in assets_agg.items():
        if data['bodies']:
            widths, heights = zip(*(i.size for i in data['bodies']))
            total_h = sum(heights)
            max_w = max(widths)
            merged_img = Image.new('RGB', (max_w, total_h), (255, 255, 255))
            y_off = 0
            for img in data['bodies']:
                merged_img.paste(img, (0, y_off))
                y_off += img.height
            
            merged_img.save(os.path.join(extracted_assets_dir, f"{key}.png"))
            asset_count += 1
        
        full_caption = " ".join(data['captions'])
        final_asset_captions[key] = full_caption
        
        type_str, id_str = key.split('_')
        ref_map.append(f"{type_str} {id_str} -> {key}")
        if type_str == "Figure": ref_map.append(f"Fig. {id_str} -> {key}")
        elif type_str == "Table": ref_map.append(f"Tab. {id_str} -> {key}")

    ref_map_str = "\n".join(ref_map)

    print("ğŸ“ æå–æ­£æ–‡æ–‡æœ¬...")
    raw_paragraph_stream = [] 
    raw_paragraph_stream.extend(meta_info_blocks)
    
    header_pattern = re.compile(r'^(\d+(\.\d+)*\.?|[IVX]+\.|[A-Z]\.)\s+|^(Abstract|References|Introduction|Conclusion|Method)', re.IGNORECASE)

    for p_idx, page in enumerate(doc):
        page_asset_inserts = []
        page_items = verified_data.get(p_idx, [])
        ignore_rects = []
        content_rect = page.rect # é»˜è®¤å…¨é¡µï¼Œä¼šè¢«ä¸‹é¢çš„ ContentArea è¦†ç›–

        for item in page_items:
            if item['type'] == 'ContentArea': 
                content_rect = item['rect']
            elif item['type'] in ['Mask', 'Title', 'Author']: 
                ignore_rects.append(item['rect'])
            else:
                ignore_rects.append(item['rect'])
                key = f"{item['type']}_{item['id']}"
                page_asset_inserts.append({
                    "rect": item['rect'],
                    "text": f"[[ASSET_INSERT: {key}]]",
                    "id": key
                })

        unique_inserts = {}
        for ins in page_asset_inserts:
            k = ins['id']
            if k not in unique_inserts or ins['rect'].y0 < unique_inserts[k]['rect'].y0:
                unique_inserts[k] = ins
        sorted_inserts = sorted(unique_inserts.values(), key=lambda x: x['rect'].y0)

        raw_blocks = page.get_text("blocks", clip=content_rect)
        mixed_blocks = []
        mid_x = (content_rect.x0 + content_rect.x1) / 2
        left_col, right_col = [], []
        for b in raw_blocks:
            if (b[0] + b[2]) / 2 < mid_x: left_col.append(b)
            else: right_col.append(b)
        left_col.sort(key=lambda b: (b[1], b[0]))
        right_col.sort(key=lambda b: (b[1], b[0]))
        sorted_text_blocks = left_col + right_col

        for b in sorted_text_blocks:
            bbox = fitz.Rect(b[:4])
            text = b[4].strip()
            is_masked = False
            for ir in ignore_rects:
                if is_box_in_rect(bbox, ir, 0.6): 
                    is_masked = True; break
            
            if not is_masked and text:
                mixed_blocks.append({
                    "type": "text",
                    "y_sort": bbox.y0 + (0 if bbox.x0 < mid_x else 10000),
                    "text": text
                })

        for ins in sorted_inserts:
            bbox = ins['rect']
            mixed_blocks.append({
                "type": "asset_tag",
                "y_sort": bbox.y0 + (0 if bbox.x0 < mid_x else 10000),
                "text": ins['text']
            })
            
        mixed_blocks.sort(key=lambda x: x['y_sort'])

        for b in mixed_blocks:
            text = b['text']
            if b['type'] == "text":
                text = re.sub(r'-\n', '', text)
                text = text.replace('\n', ' ')
                lines = text.split('\n')
                first_line = lines[0].strip()
                if header_pattern.match(first_line) and len(first_line) < 80:
                    raw_paragraph_stream.append(f"[[HEADER: {first_line}]]")
                    if len(lines) > 1: raw_paragraph_stream.append(" ".join(lines[1:]))
                else:
                    raw_paragraph_stream.append(text)
            else:
                raw_paragraph_stream.append(text)

    merged_text_blocks = smart_merge_paragraphs(raw_paragraph_stream)

    assets_xml_snippets = []
    sorted_keys = sorted(assets_agg.keys(), key=lambda k: (k.split('_')[0], int(k.split('_')[1])))
    
    assets_xml_snippets.append("\n\n--- ASSETS METADATA ---\n")
    for key in sorted_keys:
        cap = final_asset_captions[key]
        if cap:
            assets_xml_snippets.append(f"[[ASSET_CAPTION: {key} | {cap}]]")
        else:
            assets_xml_snippets.append(f"[[ASSET_PLACEHOLDER: {key}]]")
    
    final_content = "\n\n".join(merged_text_blocks) + "\n\n" + "\n".join(assets_xml_snippets)
    
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(f"[[REF_MAP_START]]\n{ref_map_str}\n[[REF_MAP_END]]\n\n")
        f.write(final_content)

    vis_final_dir = os.path.join(vis_output_root, clean_name)
    return final_content, txt_path, vis_final_dir, asset_count

# --- è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—æ–‡æœ¬æŒ‡çº¹ ---
def compute_hash(text):
    return hashlib.md5(text.encode('utf-8')).hexdigest()

# --- è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½åˆ†ç¦»ï¼ˆä¿®å¤ Assets è¢«è¯¯åçš„é—®é¢˜ï¼‰---
# --- è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½åˆ†ç¦» (å››æ®µå¼åˆ‡åˆ†ï¼šMeta / Body / Assets / Refs) ---
def split_content_smart(text):
    """
    å°†æ–‡æœ¬åˆ‡åˆ†ä¸ºå››éƒ¨åˆ†ï¼Œç¡®ä¿æ¯ä¸€éƒ¨åˆ†éƒ½èƒ½è¢«ç‹¬ç«‹å¤„ç†ï¼š
    1. å…ƒæ•°æ® (Meta) -> å¿…é¡»å•ç‹¬ç¿»è¯‘ï¼Œé˜²æ­¢è¢«æ­£æ–‡åæ²¡
    2. èµ„æºè¯´æ˜ (Assets) -> å¿…é¡»ç¿»è¯‘
    3. å‚è€ƒæ–‡çŒ® (Refs) -> è·³è¿‡
    4. æ­£æ–‡ (Body) -> åˆ‡åˆ†ç¿»è¯‘
    """
    # --- 1. å‰¥ç¦» ASSETS METADATA (ä»å°¾éƒ¨æ‰¾) ---
    asset_marker = "--- ASSETS METADATA ---"
    assets_part = ""
    content_remaining = text
    
    if asset_marker in text:
        parts = text.rsplit(asset_marker, 1)
        if len(parts) == 2:
            content_remaining = parts[0]
            assets_part = asset_marker + parts[1] # ä¿ç•™æ ‡è®°å¤´

    # --- 2. å‰¥ç¦» References (åœ¨å‰©ä½™ä¸­æ‰¾) ---
    # å…¼å®¹ [[HEADER: References]] æˆ– [[HEADER: REFERENCE]] ç­‰
    ref_pattern = re.compile(r'(\[\[HEADER:\s*References?.*?\]\])', re.IGNORECASE)
    split_parts = ref_pattern.split(content_remaining, maxsplit=1)
    
    body_with_meta = ""
    ref_part = ""
    
    if len(split_parts) >= 3:
        # split_parts[0]: æ­£æ–‡
        # split_parts[1]: æ ‡é¢˜ ([[HEADER: References]])
        # split_parts[2]: å‚è€ƒæ–‡çŒ®åˆ—è¡¨å†…å®¹
        body_with_meta = split_parts[0].strip()
        ref_part = split_parts[1] + split_parts[2]
    else:
        body_with_meta = content_remaining.strip()

    # --- 3. å‰¥ç¦» Meta Data (ä»å¤´éƒ¨æ‰¾) ---
    # åŒ¹é…è¿ç»­çš„ [[META_...]] å—
    meta_pattern = re.compile(r'(\[\[META_.*?:.*?\]\]\s*)+')
    meta_match = meta_pattern.match(body_with_meta)
    
    meta_part = ""
    body_part = body_with_meta
    
    if meta_match:
        meta_part = meta_match.group(0).strip()
        # ä»åŒ¹é…ç»“æŸçš„ä½ç½®å¼€å§‹æˆªå–æ­£æ–‡
        body_part = body_with_meta[meta_match.end():].strip()

    # è¿”å› 4 ä¸ªéƒ¨åˆ†
    return meta_part, body_part, assets_part, ref_part

def split_text_into_chunks_with_layout(text, max_chars):
    """
    åˆ‡åˆ†æ–‡æœ¬ï¼ŒåŒæ—¶æå– [[ASSET_INSERT]] æ ‡è®°ã€‚
    è¿”å›: (chunks, layout_map)
    layout_map = { chunk_index: [asset_id1, asset_id2] }
    """
    header_pattern = re.compile(r'(\[\[HEADER:.*?\]\])', re.IGNORECASE)
    # æ­£åˆ™ç”¨äºæå–å¹¶ç§»é™¤ INSERT æ ‡è®°
    insert_pattern = re.compile(r'\[\[ASSET_INSERT:\s*(.*?)\]\]')
    
    segments = header_pattern.split(text)
    final_chunks = []
    layout_map = {}
    
    current_chunk_idx = 0
    
    for seg in segments:
        seg = seg.strip()
        if not seg: continue
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰ Insert æ ‡è®°
        found_inserts = insert_pattern.findall(seg)
        # ç§»é™¤æ ‡è®°ï¼Œå‡€åŒ–æ–‡æœ¬
        clean_seg = insert_pattern.sub('', seg).strip()
        
        if not clean_seg and not found_inserts: continue # åªæœ‰æ ‡è®°ä¸”è¢«ç§»é™¤åä¸ºç©ºï¼Œè·³è¿‡? ä¸ï¼Œæ ‡è®°ä½ç½®å¾ˆé‡è¦
        
        # 2. å¦‚æœæ˜¯ Header -> ç‹¬ç«‹æˆå—
        if header_pattern.match(seg): # æ³¨æ„ï¼šè¿™é‡ŒåŒ¹é…çš„æ˜¯åŸå§‹ segï¼Œæ‰€ä»¥ Header é‡Œä¸åº”è¯¥æœ‰ Insert æ ‡è®°ï¼Œå‡å¦‚æœ‰ä¹Ÿè¦å¤„ç†
             # Header è¿˜æ˜¯åŸæ ·ä¿ç•™ï¼Œå‡è®¾ Header é‡Œæ²¡æœ‰ Insert
             final_chunks.append(clean_seg)
             if found_inserts:
                 if current_chunk_idx not in layout_map: layout_map[current_chunk_idx] = []
                 layout_map[current_chunk_idx].extend(found_inserts)
             current_chunk_idx += 1
             
        # 3. æ­£æ–‡ -> æŒ‰é•¿åº¦åˆ‡åˆ†
        else:
            paragraphs = clean_seg.split('\n\n')
            buffer = []
            buffer_len = 0
            
            # å¦‚æœè¿™ä¸€æ®µå…¨æ˜¯ Insert æ ‡è®°ï¼Œæ–‡æœ¬ä¸ºç©º
            if not clean_seg and found_inserts:
                # æŠŠå®ƒæŒ‚åœ¨å½“å‰å³å°†åœ¨ç”Ÿæˆçš„ chunk (æˆ–è€…ä¸Šä¸€ä¸ª)
                # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æŒ‚åœ¨ "ä¸‹ä¸€ä¸ªå³å°†ç”Ÿæˆçš„ chunk" ç´¢å¼•ä¸Š
                if current_chunk_idx not in layout_map: layout_map[current_chunk_idx] = []
                layout_map[current_chunk_idx].extend(found_inserts)
                continue

            for p in paragraphs:
                p = p.strip()
                if not p: continue
                
                if buffer_len + len(p) > max_chars and buffer:
                    final_chunks.append("\n\n".join(buffer))
                    # æ³¨æ„ï¼šå¦‚æœåˆšæ‰çš„ inserts æ˜¯åœ¨è¿™ä¸ªæ®µè½é‡Œçš„ï¼Œé€»è¾‘ä¸Šå¾ˆéš¾ç²¾ç¡®åˆ°â€œæ®µè½çº§â€ã€‚
                    # æˆ‘ä»¬ç›®å‰çš„ç²’åº¦æ˜¯ Chunk çº§ã€‚
                    # ç®€å•ç­–ç•¥ï¼šå¦‚æœè¿™ä¸ªå¤§æ®µé‡Œæœ‰ insertï¼Œæˆ‘ä»¬ç»Ÿä¸€æŒ‚åœ¨ç¬¬ä¸€ä¸ª chunk ä¸Šï¼Œ
                    # æˆ–è€…æŒ‚åœ¨å½“å‰ chunkã€‚
                    # æ”¹è¿›ç­–ç•¥ï¼šfound_inserts æ˜¯å±äºæ•´ä¸ª seg çš„ã€‚æˆ‘ä»¬æŠŠå®ƒæŒ‚åœ¨è¿™ä¸ª seg ç”Ÿæˆçš„ *ç¬¬ä¸€ä¸ª* chunk ä¸Šã€‚
                    if found_inserts:
                         if current_chunk_idx not in layout_map: layout_map[current_chunk_idx] = []
                         layout_map[current_chunk_idx].extend(found_inserts)
                         found_inserts = [] # åªè¦æŒ‚è½½ä¸€æ¬¡
                    
                    current_chunk_idx += 1
                    buffer = []
                    buffer_len = 0
                
                buffer.append(p)
                buffer_len += len(p)
            
            if buffer:
                final_chunks.append("\n\n".join(buffer))
                if found_inserts: # å¤„ç†å‰©ä½™çš„ (æˆ–è€…è¯¥æ®µåªæœ‰ä¸€ä¸ª chunk çš„æƒ…å†µ)
                     if current_chunk_idx not in layout_map: layout_map[current_chunk_idx] = []
                     layout_map[current_chunk_idx].extend(found_inserts)
                current_chunk_idx += 1
                
    return final_chunks, layout_map

# --- æ ¸å¿ƒ LLM è°ƒç”¨å‡½æ•° (åº”ç”¨æ–°çš„åˆ‡åˆ†é€»è¾‘) ---
def run_smart_analysis(full_text_path_or_content: str, output_path: str, cache_path: str = None):
    # ã€æ¨¡å¼é…ç½®ã€‘
    API_KEY = "ollama" 
    BASE_URL = "http://localhost:11434/v1"
    MODEL_NAME = "qwen2.5:7b"
    
    from openai import OpenAI

    if os.path.isfile(full_text_path_or_content):
         with open(full_text_path_or_content, 'r', encoding='utf-8') as f: content = f.read()
    else:
        content = full_text_path_or_content

    ref_map_str = ""
    body_text = content
    map_match = re.search(r'\[\[REF_MAP_START\]\]\n(.*?)\n\[\[REF_MAP_END\]\]', content, re.DOTALL)
    if map_match:
        ref_map_str = map_match.group(1)
        body_text = content.replace(map_match.group(0), "").strip()
    
    meta_text, body_text, assets_text, raw_refs_text = split_content_smart(body_text)
    
    raw_chunks = []
    layout_map_global = {} 
    
    if meta_text: raw_chunks.append({"text": meta_text, "type": "meta"})
        
    if body_text:
        body_parts, local_layout_map = split_text_into_chunks_with_layout(body_text, MAX_CHUNK_CHARS)
        offset = len(raw_chunks) 
        for idx, part in enumerate(body_parts):
            raw_chunks.append({"text": part, "type": "body"})
            if idx in local_layout_map:
                layout_map_global[idx + offset] = local_layout_map[idx]
            
    if assets_text: raw_chunks.append({"text": assets_text, "type": "asset"})

    # é˜¶æ®µä¸€
    print(f"ğŸ“‹ [é˜¶æ®µä¸€] ç¼–æ’ä»»åŠ¡: æ€»ç‰‡æ®µ {len(raw_chunks)} ä¸ª")
    
    old_tasks_map = {}
    if cache_path and os.path.exists(cache_path):
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                old_json = json.load(f)
                for t in old_json.get("tasks", []):
                    old_tasks_map[t["chunk_hash"]] = t
        except: pass

    current_tasks = []
    for i, item in enumerate(raw_chunks):
        c_text = item["text"]
        c_type = item["type"]
        h = compute_hash(c_text)
        cached_task = old_tasks_map.get(h)
        if cached_task:
            task_entry = cached_task
            task_entry["id"] = i
            if "type" not in task_entry: task_entry["type"] = c_type
            if task_entry["status"] == "failed":
                task_entry["status"] = "pending"
                print(f"   ğŸ”¹ Part {i+1}: ä¹‹å‰å¤±è´¥ï¼Œå·²é‡ç½®ä¸º pending")
        else:
            task_entry = { "id": i, "type": c_type, "chunk_hash": h, "status": "pending", "src": c_text, "trans": "" }
        current_tasks.append(task_entry)

    # é˜¶æ®µä¸€ç‚¹äº”ï¼šäººå·¥å®¡æŸ¥
    suspicious_tasks = [t for t in current_tasks if t.get("status") == "suspicious"]
    
    if suspicious_tasks:
        print(f"\nâš ï¸ æ£€æµ‹åˆ° {len(suspicious_tasks)} ä¸ª 'suspicious' ä»»åŠ¡ï¼Œè¯·å®¡æ ¸ï¼š")
        for st in suspicious_tasks:
            print("=" * 60)
            print(f"ã€ID: {st['id']} | Type: {st['type']}ã€‘")
            # --- ã€ä¿®æ”¹ç‚¹ã€‘å®Œæ•´æ˜¾ç¤ºï¼Œä¸å†æˆªæ–­ ---
            print("ğŸ”» åŸæ–‡:")
            print(st['src']) 
            print("-" * 30)
            print("ğŸ”» è¯‘æ–‡:")
            print(st['trans']) 
            print("=" * 60)
            
            while True:
                user_choice = input("ğŸ‘‰ æ“ä½œ? (y=é€šè¿‡ / n=é‡è¯‘ / s=è·³è¿‡): ").strip().lower()
                if user_choice == 'y':
                    st['status'] = 'success'
                    print("   âœ… Marked as Success")
                    break
                elif user_choice == 'n':
                    st['status'] = 'pending'
                    st['trans'] = ""
                    print("   ğŸ”„ Marked as Pending")
                    break
                elif user_choice == 's':
                    print("   â­ï¸ Skipped")
                    break
        
        _save_cache(cache_path, MODEL_NAME, current_tasks, raw_refs_text, layout_map_global)

    # é˜¶æ®µäºŒ
    pending_tasks = [t for t in current_tasks if t["status"] == "pending"]
    if pending_tasks:
        print(f"\nğŸš€ [é˜¶æ®µäºŒ] å¼€å§‹æ¨ç† (å‰©ä½™ {len(pending_tasks)} ä¸ª)...")
        client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
        PROMPT_MAP = {
            "meta": SYSTEM_PROMPT_META,
            "body": SYSTEM_PROMPT_BODY.replace("{ref_map_str}", ref_map_str),
            "asset": SYSTEM_PROMPT_ASSET.replace("{ref_map_str}", ref_map_str)
        }
        for task in current_tasks:
            if task["status"] != "pending": continue
            print(f"   âš¡ Part {task['id']+1}/{len(current_tasks)} [{task['type'].upper()}] ...", end="", flush=True)
            
            messages = [
                {"role": "system", "content": PROMPT_MAP.get(task['type'], PROMPT_MAP["body"])},
                {"role": "user", "content": task["src"]}
            ]
            
            success = False
            for attempt in range(3):
                try:
                    response = client.chat.completions.create(model=MODEL_NAME, messages=messages, temperature=0.1)
                    res_text = response.choices[0].message.content
                    res_text = re.sub(r'^```xml\s*', '', res_text)
                    res_text = re.sub(r'```$', '', res_text)
                    if res_text:
                        task["trans"] = res_text.strip()
                        task["status"] = "success"
                        print(" âœ…")
                        success = True
                        break
                except Exception as e:
                    print(f" âš ï¸ {e}")
                    time.sleep(2)
            if not success:
                task["status"] = "failed"
                print(" âŒ")
            if cache_path: _save_cache(cache_path, MODEL_NAME, current_tasks, raw_refs_text, layout_map_global)
    else:
        print("\nğŸ‰ æ— éœ€æ–°å¢æ¨ç†ã€‚")

    # é˜¶æ®µä¸‰
    print("ğŸ’¾ [é˜¶æ®µä¸‰] åˆ·æ–°ç»“æœæ–‡ä»¶...")
    final_body = "\n".join([t["trans"] for t in current_tasks if t["status"] == "success"])
    final_refs = ""
    if raw_refs_text:
        final_refs = f"\n<header_block><src>References</src><trans>å‚è€ƒæ–‡çŒ®</trans></header_block>\n"
        clean_ref_content = re.sub(r'\[\[HEADER:.*?\]\]', '', raw_refs_text).strip()
        final_refs += f"<ref_block><src>{clean_ref_content}</src></ref_block>"

    with open(output_path, 'w', encoding='utf-8') as f: 
        f.write(final_body + "\n" + final_refs)
    return output_path

def _save_cache(path, model, tasks, refs, layout):
    if not path: return
    structure = { "model": model, "updated_at": time.strftime("%Y-%m-%d %H:%M:%S"), "tasks": tasks, "raw_references": refs, "layout_map": layout }
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(structure, f, ensure_ascii=False, indent=2)

# è¾…åŠ©å‡½æ•°ï¼šä¿å­˜ Cacheï¼Œé¿å…ä»£ç é‡å¤
def _save_cache(path, model, tasks, refs, layout):
    if not path: return
    structure = {
        "model": model,
        "updated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        "tasks": tasks,
        "raw_references": refs,
        "layout_map": layout
    }
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(structure, f, ensure_ascii=False, indent=2)

# --- è¾…åŠ©å‡½æ•°ï¼šä»»åŠ¡åˆ‡åˆ† (å‡çº§ç‰ˆï¼šå¼ºåˆ¶éš”ç¦»æ ‡é¢˜) ---
def split_text_into_chunks(text, max_chars):
    """
    å°†æ–‡æœ¬åˆ‡åˆ†ä¸º LLM ä»»åŠ¡ç‰‡æ®µã€‚
    ç­–ç•¥ï¼š
    1. é‡åˆ° [[HEADER:...]] å¿…é¡»å¼ºåˆ¶åˆ‡æ–­ï¼Œç‹¬ç«‹æˆä¸€ä¸ªä»»åŠ¡ã€‚
    2. æ™®é€šæ­£æ–‡å†æŒ‰ max_chars è¿›è¡Œé•¿åº¦åˆ‡åˆ†ã€‚
    """
    # 1. ä½¿ç”¨æ­£åˆ™ä¿ç•™åˆ†éš”ç¬¦çš„æ–¹å¼åˆ‡åˆ†
    # æ•è·ç»„ () ä¼šè®© split ä¿ç•™åˆ†éš”ç¬¦æœ¬èº«
    header_pattern = re.compile(r'(\[\[HEADER:.*?\]\])', re.IGNORECASE)
    segments = header_pattern.split(text)
    
    final_chunks = []
    
    for seg in segments:
        seg = seg.strip()
        if not seg: continue
        
        # --- æƒ…å†µ A: æ˜¯æ ‡é¢˜ -> å¼ºåˆ¶ç‹¬ç«‹ ---
        if header_pattern.match(seg):
            final_chunks.append(seg)
            
        # --- æƒ…å†µ B: æ˜¯æ­£æ–‡ -> æŒ‰é•¿åº¦åˆ‡åˆ† ---
        else:
            # åŸæœ‰çš„æŒ‰æ®µè½é•¿åº¦åˆå¹¶é€»è¾‘
            paragraphs = seg.split('\n\n')
            buffer = []
            buffer_len = 0
            
            for p in paragraphs:
                p = p.strip()
                if not p: continue
                
                # å¦‚æœå½“å‰ç¼“å†² + æ–°æ®µè½ > æœ€å¤§é•¿åº¦ï¼Œåˆ™å°åŒ…
                if buffer_len + len(p) > max_chars and buffer:
                    final_chunks.append("\n\n".join(buffer))
                    buffer = []
                    buffer_len = 0
                
                buffer.append(p)
                buffer_len += len(p)
            
            # å¤„ç†æ®‹ç•™ buffer
            if buffer:
                final_chunks.append("\n\n".join(buffer))
                
    return final_chunks

# --- HTML ç”Ÿæˆå™¨ (æœ€ç»ˆå¢å¼ºç‰ˆï¼šä¿®å¤æ ‡é¢˜æ¼ç½‘ã€å…¬å¼ä¸¢å¤±ã€å›¾è¡¨é”™ä½) ---
def generate_html_report(llm_result_path: str, paper_vis_dir: str):
    # 1. è·¯å¾„å‡†å¤‡
    cache_path = llm_result_path.replace("_llm_result.txt", "_llm_cache.json")
    if not os.path.exists(cache_path):
        return "Error: æ‰¾ä¸åˆ°ç¼“å­˜æ–‡ä»¶ï¼Œæ— æ³•æ‰§è¡Œé«˜çº§å¯è§†åŒ–ã€‚"
    
    # è·å–è®ºæ–‡åç§° (å³æ–‡ä»¶å¤¹å)
    raw_name = os.path.basename(paper_vis_dir)
    html_path = os.path.join(paper_vis_dir, f"{raw_name}_Report.html")
    
    # --- ã€æ–°å¢ã€‘èµ„æºæ¬è¿å‡†å¤‡ ---
    # ç›®æ ‡ç›®å½•: ./vis_output/{PaperName}/assets
    vis_assets_dest = os.path.join(paper_vis_dir, "assets")
    if not os.path.exists(vis_assets_dest):
        os.makedirs(vis_assets_dest, exist_ok=True)
        
    # æºç›®å½•æ¨å¯¼: å‡è®¾ extracted_output ä¸ vis_output åœ¨åŒä¸€çº§æ ¹ç›®å½•ä¸‹
    # paper_vis_dir é€šå¸¸æ˜¯ .../vis_output/{PaperName}
    # æˆ‘ä»¬éœ€è¦æ‰¾åˆ° .../extracted_output/{PaperName}/assets
    root_dir = os.path.dirname(os.path.dirname(paper_vis_dir)) 
    extracted_assets_src = os.path.join(root_dir, "extracted_output", raw_name, "assets")
    
    # è°ƒè¯•ä¿¡æ¯ (å¯é€‰)
    # print(f"DEBUG: Copying assets from {extracted_assets_src} to {vis_assets_dest}")
    
    # è¯»å– Cache JSON
    try:
        with open(cache_path, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
    except Exception as e:
        return f"JSON è¯»å–å¤±è´¥: {e}"

    tasks = cache_data.get("tasks", [])
    raw_refs = cache_data.get("raw_references", "")
    layout_map = cache_data.get("layout_map", {})

    # ==========================================================================
    # 2. æ„å»ºèµ„æºå­—å…¸ & æ‰§è¡Œæ¬è¿ (Copy)
    # ==========================================================================
    meta_task = None
    asset_task = None
    body_tasks = []

    for t in tasks:
        if t['type'] == 'meta': meta_task = t
        elif t['type'] == 'asset': asset_task = t
        else: body_tasks.append(t)

    assets_map = {}
    
    # å®šä¹‰æ¬è¿å‡½æ•°
    def copy_and_get_rel_path(asset_id):
        filename = f"{asset_id}.png"
        src_file = os.path.join(extracted_assets_src, filename)
        dst_file = os.path.join(vis_assets_dest, filename)
        
        # æ‰§è¡Œæ‹·è´
        if os.path.exists(src_file):
            shutil.copy2(src_file, dst_file)
        
        # è¿”å› HTML ç”¨çš„ç›¸å¯¹è·¯å¾„
        return f"./assets/{filename}"

    if asset_task:
        src_full = asset_task.get('src', '')
        trans_full = asset_task.get('trans', '')
        
        # A. Captioned Assets (æœ‰æ ‡é¢˜çš„å›¾è¡¨)
        src_iter = re.finditer(r'\[\[ASSET_CAPTION:\s*(.*?)\s*\|\s*(.*?)\]\]', src_full, re.DOTALL)
        for m in src_iter:
            aid = m.group(1).strip()
            src_txt = m.group(2).strip()
            
            trans_match = re.search(fr'<asset id=["\']?{re.escape(aid)}["\']?>(.*?)</asset>', trans_full, re.DOTALL)
            trans_txt = trans_match.group(1).strip() if trans_match else "(æœªæ‰¾åˆ°è¯‘æ–‡)"
            
            # --- æ ¸å¿ƒï¼šåœ¨è¿™é‡Œæ¬è¿ ---
            rel_path = copy_and_get_rel_path(aid)
            
            assets_map[aid] = {
                "id": aid, "type": "captioned", "src": src_txt, "trans": trans_txt, "path": rel_path
            }
            
        # B. Placeholder Assets (æ— æ ‡é¢˜çš„å…¬å¼/æ’å›¾)
        ph_iter = re.finditer(r'\[\[ASSET_PLACEHOLDER:\s*(.*?)\]\]', src_full)
        for m in ph_iter:
            aid = m.group(1).strip()
            if aid not in assets_map:
                # --- æ ¸å¿ƒï¼šåœ¨è¿™é‡Œæ¬è¿ ---
                rel_path = copy_and_get_rel_path(aid)
                assets_map[aid] = {
                    "id": aid, "type": "placeholder", "src": "", "trans": "", "path": rel_path
                }

    # ==========================================================================
    # 3. æ¸²æŸ“é€»è¾‘ (ç‰©ç†ä¼˜å…ˆ + é€»è¾‘å¼•ç”¨å…œåº•)
    # ==========================================================================
    def clean_xml_and_headers(text):
        if not text: return ""
        text = re.sub(r'^```xml', '', text).replace('```', '')
        text = re.sub(r'\[\[HEADER:\s*(.*?)\]\]', r'\1', text)
        text = text.replace('<header>', '').replace('</header>', '') 
        text = text.replace('<p>', '').replace('</p>', '<br>')
        text = re.sub(r'\[\[LINK:\s*([^\|]+)\|(.*?)\]\]', r'<a href="#\1" class="internal-link">\2</a>', text)
        def ref_sub(m):
            full_str = m.group(1) 
            first_num = re.search(r'\d+', full_str)
            if first_num: return f'<a href="#ref-{first_num.group(0)}" class="citation-mark">{full_str}</a>'
            return f'<span class="citation-mark">{full_str}</span>'
        text = re.sub(r'(\[\s*\d+(?:[\s,\-~]+\d+)*\s*\])', ref_sub, text)
        return text

    # --- HTML ç»„è£… ---
    html_meta = ""
    if meta_task:
        m_src = meta_task.get('src', '')
        m_trans = meta_task.get('trans', '')
        t_en = re.search(r'\[\[META_TITLE:(.*?)\]\]', m_src, re.DOTALL)
        t_en = t_en.group(1).strip() if t_en else ""
        t_zh = re.search(r'<meta_title>(.*?)</meta_title>', m_trans, re.DOTALL)
        t_zh = t_zh.group(1).strip() if t_zh else ""
        a_en = re.search(r'\[\[META_AUTHOR:(.*?)\]\]', m_src, re.DOTALL)
        a_en = a_en.group(1).strip() if a_en else ""
        a_zh = re.search(r'<meta_author>(.*?)</meta_author>', m_trans, re.DOTALL)
        a_zh = a_zh.group(1).strip() if a_zh else ""
        html_meta = f"""<div class="meta-section"><h1 class="meta-title-en">{t_en}</h1><h1 class="meta-title-zh">{t_zh}</h1><div class="meta-author-en">{a_en}</div><div class="meta-author-zh">{a_zh}</div></div><hr class="meta-divider">"""

    html_body = ""
    placed_assets = set()
    
    for task in body_tasks:
        global_task_id = task['id']
        layout_assets = layout_map.get(str(global_task_id), [])
        
        # 1. ç‰©ç†ä½ç½®æ’å…¥
        for aid in layout_assets:
            if aid in assets_map and aid not in placed_assets:
                asset = assets_map[aid]
                html_body += render_asset_html(aid, asset)
                placed_assets.add(aid)
        
        # 2. æ–‡æœ¬
        src_txt = task.get('src', '')
        trans_txt = task.get('trans', '')
        is_header_src = "[[HEADER:" in src_txt
        is_header_trans = "[[HEADER:" in trans_txt or "<header>" in trans_txt
        row_class = "header-row" if (is_header_src or is_header_trans) else "text-row"
        display_src = re.sub(r'\[\[HEADER:\s*(.*?)\]\]', r'\1', src_txt)
        display_src = re.sub(r'(\[\s*\d+(?:[\s,\-~]+\d+)*\s*\])', r'<span class="citation-mark-src">\1</span>', display_src)
        display_trans = clean_xml_and_headers(trans_txt)
        
        html_body += f"""<div class="row {row_class}"><div class="col-src">{display_src}</div><div class="col-trans">{display_trans}</div></div>"""
        
        # 3. é€»è¾‘å¼•ç”¨è¡¥æ¼
        mentions = re.findall(r'\[\[LINK:\s*([^\|]+)\|', src_txt)
        for mid in mentions:
            if mid in assets_map and mid not in placed_assets:
                asset = assets_map[mid]
                html_body += render_asset_html(mid, asset)
                placed_assets.add(mid)

    # 4. å‰©ä½™èµ„æº
    remaining = [k for k in assets_map.keys() if k not in placed_assets]
    if remaining:
        html_body += '<div class="row"><div style="width:100%; text-align:center; color:#999; padding:20px;">--- é™„å½•èµ„æº (æœªåœ¨æ­£æ–‡ä½ç½®æˆ–å¼•ç”¨ä¸­æ£€æµ‹åˆ°) ---</div></div>'
        for mid in remaining:
            asset = assets_map[mid]
            html_body += render_asset_html(mid, asset)

    html_refs = ""
    if raw_refs:
        refs_content = re.sub(r'\[\[HEADER:.*?\]\]', '', raw_refs).strip()
        ref_entries = re.split(r'\[(\d+)\]', refs_content)
        ref_items = ""
        for i in range(1, len(ref_entries), 2):
            rid = ref_entries[i]
            rtext = ref_entries[i+1].strip()
            ref_items += f"""<div class="ref-item" id="ref-{rid}"><div class="ref-id">[{rid}]</div><div class="ref-text">{rtext}</div></div>"""
        html_refs = f"""<div class="ref-section"><h2 class="ref-title">References</h2><div class="ref-list">{ref_items}</div></div>"""

    # --- HTML Template ---
    full_html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>{raw_name}</title>
    <style>
        :root {{ --primary: #2c3e50; --accent: #3498db; --bg: #f8f9fa; --border: #e0e0e0; --header-bg: #eef6fc; --header-text: #2980b9; }}
        body {{ font-family: "Segoe UI", Roboto, "Microsoft YaHei", sans-serif; margin: 0; background: var(--bg); color: #333; line-height: 1.6; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: #fff; box-shadow: 0 0 20px rgba(0,0,0,0.05); }}
        .meta-section {{ padding: 40px; text-align: center; background: #fff; }}
        .meta-title-en {{ font-size: 1.8em; color: #2c3e50; margin-bottom: 10px; font-weight: 700; }}
        .meta-title-zh {{ font-size: 1.6em; color: #34495e; margin-top: 0; margin-bottom: 20px; font-weight: 400; }}
        .meta-author-en {{ font-size: 1em; color: #7f8c8d; font-style: italic; }}
        .meta-author-zh {{ font-size: 1em; color: #16a085; font-weight: bold; margin-top: 5px; }}
        .meta-divider {{ border: 0; border-top: 1px solid #eee; margin: 0; }}
        .row {{ display: flex; border-bottom: 1px solid var(--border); }}
        .col-src {{ flex: 1; padding: 20px; border-right: 1px solid var(--border); color: #555; font-family: "Cambria", serif; font-size: 15px; background: #fff; }}
        .col-trans {{ flex: 1; padding: 20px; color: #111; font-size: 16px; background: #fdfdfd; }}
        .header-row {{ background-color: var(--header-bg) !important; border-bottom: 2px solid #d6eaf8; }}
        .header-row .col-src, .header-row .col-trans {{ font-weight: bold; color: var(--header-text); font-size: 1.2em; background: transparent; }}
        .asset-row {{ display: block; background: #f4f4f4; padding: 20px; border-bottom: 1px solid #ddd; }}
        .asset-card {{ background: #fff; max-width: 90%; margin: 0 auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); overflow: hidden; }}
        .placeholder-card {{ max-width: 60%; }} 
        .asset-header {{ background: #f8f9fa; padding: 10px 20px; font-weight: bold; color: #555; border-bottom: 1px solid #eee; }}
        .asset-header-mini {{ background: #f8f9fa; padding: 5px 15px; font-size: 0.9em; color: #888; border-bottom: 1px solid #eee; }}
        .asset-tag {{ background: #3498db; color: #fff; padding: 2px 6px; border-radius: 4px; font-size: 0.8em; margin-right: 5px; }}
        .asset-img {{ display: block; max-width: 100%; max-height: 600px; margin: 0 auto; }}
        .asset-img-raw {{ display: block; max-width: 100%; margin: 10px auto; }}
        .asset-desc-box {{ padding: 20px; background: #fffdf5; border-top: 1px solid #eee; }}
        .asset-desc-en {{ font-style: italic; color: #666; margin-bottom: 10px; font-size: 0.95em; border-bottom: 1px dashed #ddd; padding-bottom: 8px; }}
        .asset-desc-zh {{ font-weight: 500; color: #2c3e50; }}
        .ref-section {{ padding: 40px; background: #fff; border-top: 4px solid #2c3e50; }}
        .ref-title {{ text-align: center; color: #2c3e50; margin-bottom: 30px; }}
        .ref-list {{ display: grid; grid-template-columns: 1fr; gap: 15px; }}
        .ref-item {{ display: flex; align-items: flex-start; }}
        .ref-id {{ min-width: 40px; font-weight: bold; color: #e74c3c; text-align: right; margin-right: 15px; }}
        .ref-text {{ font-size: 0.95em; color: #555; word-break: break-word; }}
        .citation-mark {{ color: #e74c3c; font-weight: bold; cursor: pointer; background: rgba(231, 76, 60, 0.1); padding: 0 2px; border-radius: 2px; font-size: 0.9em; }}
        .citation-mark-src {{ color: #999; font-size: 0.9em; }}
        .internal-link {{ color: #3498db; text-decoration: none; font-weight: 500; background: rgba(52,152,219,0.1); padding: 0 4px; border-radius: 3px; }}
        .internal-link:hover {{ background: rgba(52,152,219,0.2); text-decoration: underline; }}
        :target {{ scroll-margin-top: 20px; animation: highlight 2s ease; }}
        @keyframes highlight {{ 0% {{ background-color: #fff3cd; }} 100% {{ background-color: transparent; }} }}
    </style>
</head>
<body>
    <div class="container">
        {html_meta}
        <div class="main-content">{html_body}</div>
        {html_refs}
    </div>
</body>
</html>"""

    try:
        with open(html_path, 'w', encoding='utf-8') as f: f.write(full_html)
        return html_path
    except Exception as e:
        return f"HTML å†™å…¥å¤±è´¥: {e}"

# å•ç‹¬çš„æ¸²æŸ“å‡½æ•°
def render_asset_html(mid, asset):
    if asset["type"] == "placeholder":
        return f"""<div class="row asset-row" id="{mid}"><div class="asset-card placeholder-card"><div class="asset-header-mini">{mid}</div><img src="{asset['path']}" class="asset-img-raw" loading="lazy"></div></div>"""
    else:
        return f"""<div class="row asset-row" id="{mid}"><div class="asset-card"><div class="asset-header"><span class="asset-tag">Resource</span> {mid}</div><img src="{asset['path']}" class="asset-img" loading="lazy"><div class="asset-desc-box"><div class="asset-desc-en">{asset['src']}</div><div class="asset-desc-zh">{asset['trans']}</div></div></div></div>"""